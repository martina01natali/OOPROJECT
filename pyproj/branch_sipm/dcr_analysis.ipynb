{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d11171-dc97-4f4f-b0e7-d70389009d05",
   "metadata": {},
   "source": [
    "# DCR analysis\n",
    "\n",
    "## Processing of waveforms\n",
    "\n",
    "**GOAL**\n",
    "- count all events\n",
    "- make plot amplitude VS time to discriminate between 1 phe signals (\"real counts\" and afterpulses) and 2 phe signals (crosstalks)\n",
    "- evaluate % of afterpulses and crosstalks wrt total\n",
    "\n",
    "Notes: time axis has a physical minimum due to width of waveform\n",
    "\n",
    "**Procedure**\n",
    "- csv files of waveforms and timestamps combined\n",
    "- csv files, sliced into single waveforms\n",
    "- find minima (absolute and relative), plot them, count them (count single points of absolute minimum) and save their timestamps and amplitude\n",
    "- from amplitude value you understand if a peak is noise (crosstalk, afterpulse)\n",
    "- get amplitudes and timestamps of each minimum\n",
    "\n",
    "*Afterpulse*: happens tipically at 0.5 $\\mu$s after a real signal, and has an amplitude almost equal to 1 phe; threshold for considering an event an afterpulse of the event before is 6 $\\mu$s.  \n",
    "*Crosstalk*: single peak of amplitude 2 phe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520b95e-471f-4eb7-93fc-80b6b4612840",
   "metadata": {},
   "source": [
    "### Code from Guarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "774737d3-a0bb-4d0c-af0f-391c399006ea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# timestamp_file_name è il path relativo del file di dati a partire dalla cwd\n",
    "timestamp_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\"             # nome del file con i timestamp del trigger\n",
    "\n",
    "# definisco l'indirizzo, os.path.join() unisce un indirizzo base al nome di un file specifico\n",
    "timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)                  # getcwd() restituisce l'indirizzo della cartella nella quale è contenuto questo programma\n",
    "\n",
    "timestamp_table = pd.read_csv(timestamp_path)                                   # leggo i dati relativi ai timestamp del trigger, disponendoli in un dataframe\n",
    "                                                                                # timestamp_table.head(10) per visualizzare i dati ottenuti\n",
    "\n",
    "\n",
    "# rinomino le colonne, Event è un indice che va da 1 a 1000 (numero di eventi), mentre Delta T è il tempo trascorso dal trigger precedente\n",
    "timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "N_of_events = len(timestamp_table)                                              # Numero di waveforms (o eventi), che corrisponde al numero di eventi di trigger\n",
    "# .diff effettua la somma cumulativa di ogni riga con quelle precedente\n",
    "timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)      # axis identifica l'asse, se lungo le righe (0) o lungo le colonne (1)\n",
    "wf_data_points = 0                                                              # inizializzo la variabile wf_data_point che corrisponde al numero di punti in ogni waveform (6250)\n",
    "\n",
    "# definisco il nome del file con i dati delle waveforms, questi dati sono posti in modo contiguo ovvero in un unico file csv\n",
    "# dividendo le righe in gruppi da 6250 elementi possiamo ottenere le singole waveforms\n",
    "wf_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\"                                    \n",
    "wf_path = os.path.join(os.getcwd(),wf_file_name)                                \n",
    "wf_table = pd.DataFrame()                                                       \n",
    "\n",
    "with open(wf_file_name, 'r') as file_wf:                                        # apro il file e inserisco le righe in una lista\n",
    "    lines = file_wf.readlines()\n",
    "    for line_counter, line in enumerate(lines):                                 # cerco la riga che inizia per TIME ma prima cerco Record Lenght per ottenere il valore di wf_data_point\n",
    "        if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # wf_data_poitns sono il numero di punti in ogni waveform\n",
    "        # un altro modo per ottenere N_of_events sarebbe cercare la riga che contiene il numero di frames (\"FastFrame Count,1000\") e dividere il numero totale di righe per il numero di frames\n",
    "        \n",
    "        if line.startswith(\"TIME\"):\n",
    "            wf_table = pd.read_csv(wf_path, header = line_counter-1)            # creo il dataframe dei dati delle wf considerando come header tutte le righe fino a TIME\n",
    "            break                                                               # esco dal ciclo\n",
    "\n",
    "\n",
    "# metodo usato a lezione (meno elegante ma funziona comunque, riportato giusto per completezza)\n",
    "# line_counter = 0\n",
    "# n_line = -1\n",
    "# while n_line == -1:\n",
    "#     line = waveform_file.readline()\n",
    "#     line_counter += 1\n",
    "#     if line_counter == 100:\n",
    "#         print(\"ERROR\")\n",
    "# waveform_table = pd.read_csv(\"HPKR00030_2cicli_OV3_wf.csv\", header = n_line-1)\n",
    "\n",
    "# il metodo per il calcolo dei timestamp, allo stesso modo, è più elegante di quello trattato a lezione, che riporto qui sotto per completezza\n",
    "# timestamp_table.at[0,'Timestamp'] = timestamp_table.iloc[0]['Delta T']\n",
    "# for i in timestamp_table.index[1:]:\n",
    "#     timestamp_table.at[i,\"Timestamp\"] = timestamp_table.at[i-1,\"Timestamp\"] + timestamp_table.at[i,\"Delta T\"]\n",
    "\n",
    "# funzione di analisi per la ricerca dei minimi\n",
    "def analysis(timestamp_table, wf_table,wf_datapoints):\n",
    "# inizializzo un dataframe generale\n",
    "    general_min_list = []\n",
    "\n",
    "# cicla con un contatore che scorre su tutto il range lungo come il numero di eventi di trigger\n",
    "    for n in range(N_of_events):\n",
    "# end = '\\r' inserisce \\r alla fine della stringa, quindi riporta il puntatore all'inizio della riga in modo da sovrascrivere l'output precedente\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r')\n",
    "# nome del singolo evento analizzato in questa iterazione del ciclo\n",
    "# preparo già il nome con l'estensione giusta per quando stamperò l'immagine della waveform\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "# prima di estrarre i punti relativi alla singola waveform, convertiamo i tempi relativi in tempi assoluti\n",
    "# la colonna \"TIME\" contiene, per ogni waveform, i tempi relativi all'evento di trigger che ha avviato l'acquisizione della waveform\n",
    "# per convertire questi tempi relativi in tempi assoluti (o meglio relativi all'inizio della misura) dobbiamo aggiungere ai tempi di ogni waveform il corrispondente timestamp del trigger\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "\n",
    "# estraggo una singola waveform, ovvero 6250 punti, dalla tabella principale\n",
    "# single_wf è un DataFrame\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "\n",
    "# la funzione argrelextrema restituisce gli estremi relativi, calcolati in base all'operatore np.less_equal\n",
    "# aumentando l'ordine diminuiamo il numero di minimi trovati\n",
    "# Il range totale di punti viene suddiviso in intervalli di lunghezza proporzionale a \"order\", successivamente viene \n",
    "# estratto il minimo assoluto di ogni intervallo:\n",
    "# i minimi così trovati sono i minimi relativi restituiti dalla funzione argrelextrema\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "\n",
    "# la riga seguente serve per identificare i minimi ed inserirli nella singola waveform, in modo da vederli nei plot\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "\n",
    "# eseguo un fit di ordine 0 (quindi una media aritmetica) sui primi 250 punti, che rientrano nella zona di pre-trigger\n",
    "# (ovvero i punti precedenti all'evento di trigger), per determinare la baseline del segnale\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "# definisco una lista di minimi \"buoni\" da riempire in seguito\n",
    "        clean_minimum_list = []\n",
    "\n",
    "############################# Soglia scelta per bontà minimo ##################################\n",
    "# i minimi saranno considerati buoni se hanno ampiezza superiore a 0.006, rispetto alla baseline\n",
    "# e se hanno una distanza dall'indice precedente di almeno 50 dati\n",
    "        gap = 0.006 # mV\n",
    "        distance = 50\n",
    "###############################################################################################\n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "# un controllo sugli indici previene massimi vicini \n",
    "# (provate a togliere and (index > previous_index + 50) e vedete cosa succede)\n",
    "# se l'indice del minimo attuale dista dal suo precedente di almeno distance, allora appendo\n",
    "# l'indice del dato individuato come minimo \"buono\" alla lista clean_minimum_list\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "# aggiungo la colonna di minimi \"buoni\" alla tabella\n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "# l'indice corrispettivo sulla tabella principale è sfasato di un valore n*6250\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "\n",
    "# le seguenti linee di comando servono per graficare le singole waveforms\n",
    "# !!!!!!!!! attenzione al numero di cicli nel for, altrimenti aprite 6250 grafici !!!!!!!!!\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "        plt.savefig(figure_path)\n",
    "        plt.close()\n",
    "        \n",
    "        ####################### Evitiamo disastri ##################################\n",
    "        break\n",
    "        ############################################################################\n",
    "        \n",
    "    print('Analisi completata!!                       ')\n",
    "    return general_min_list\n",
    "\n",
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ac2ff-870f-4cf7-a433-22a2038ab205",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### My code\n",
    "\n",
    "Starting from code from Guarise, polishing and dividing in different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6289bb-5c4d-4abc-b912-7a316d36e7b8",
   "metadata": {},
   "source": [
    "**Header**\n",
    "```python\n",
    "\n",
    "def read_wf(file_name):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf detection from file_name;\n",
    "    also constructs both dataframes\n",
    "    \"\"\"\n",
    "    if file name contains 'time.csv' then do...\n",
    "    if else file_name contains wf.csv then do...\n",
    "    else NameError\n",
    "        raise\n",
    "\n",
    "def analysis_wf(timestamp_table, wf_table, wf_datapoints, threshold, distance, inplace=True):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (mV)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    \n",
    "def plot_wf(timestamp_table, wf_table, wf_datapoints, loop=True, show=False, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(mV) vs timestamp plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing.\n",
    "    \"\"\"\n",
    "\n",
    "def plot_dcr(minimum_table, hist=True):\n",
    "    \"\"\"\n",
    "    Only needs a dataframe minimum_table with the list of the minima and the related timestamps.\n",
    "    Plots an amplitude (mV) vs delta_t (ns) graph, useful to detect noise source.\n",
    "    Option hist=True plots an histogram subplot under the 2D plot, representing the integral in the vertical\n",
    "    direction of the ampli vs dt plot.\n",
    "    \"\"\"\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "256b9cf8-9082-41d9-a612-147baed5fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6a86e89-35d7-4093-8faf-6a2751c1b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_wf(fname):\n",
    "###############################################################################################\n",
    "\n",
    "if re.search(\"time.csv\", fname):\n",
    "    do ...\n",
    "elif re.search(\"wf.csv\", fname):\n",
    "    do ...\n",
    "else:\n",
    "    raise NameError(\"Please provide the path to a waveform or timestamp comma-separated file (.csv).\")\n",
    "\n",
    "# timestamp_file_name è il path relativo del file di dati a partire dalla cwd\n",
    "# timestamp_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\"             \n",
    "# nome del file con i timestamp del trigger\n",
    "\n",
    "# definisco l'indirizzo, os.path.join() unisce un indirizzo base al nome di un file specifico\n",
    "timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)                  # getcwd() restituisce l'indirizzo della cartella nella quale è contenuto questo programma\n",
    "\n",
    "timestamp_table = pd.read_csv(timestamp_path)                                   # leggo i dati relativi ai timestamp del trigger, disponendoli in un dataframe\n",
    "                                                                                # timestamp_table.head(10) per visualizzare i dati ottenuti\n",
    "\n",
    "\n",
    "# rinomino le colonne, Event è un indice che va da 1 a 1000 (numero di eventi), mentre Delta T è il tempo trascorso dal trigger precedente\n",
    "timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "N_of_events = len(timestamp_table)                                              # Numero di waveforms (o eventi), che corrisponde al numero di eventi di trigger\n",
    "# .diff effettua la somma cumulativa di ogni riga con quelle precedente\n",
    "timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)      # axis identifica l'asse, se lungo le righe (0) o lungo le colonne (1)\n",
    "wf_data_points = 0                                                              # inizializzo la variabile wf_data_point che corrisponde al numero di punti in ogni waveform (6250)\n",
    "\n",
    "# definisco il nome del file con i dati delle waveforms, questi dati sono posti in modo contiguo ovvero in un unico file csv\n",
    "# dividendo le righe in gruppi da 6250 elementi possiamo ottenere le singole waveforms\n",
    "wf_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\"                                    \n",
    "wf_path = os.path.join(os.getcwd(),wf_file_name)                                \n",
    "wf_table = pd.DataFrame()                                                       \n",
    "\n",
    "with open(wf_file_name, 'r') as file_wf:                                        # apro il file e inserisco le righe in una lista\n",
    "    lines = file_wf.readlines()\n",
    "    for line_counter, line in enumerate(lines):                                 # cerco la riga che inizia per TIME ma prima cerco Record Lenght per ottenere il valore di wf_data_point\n",
    "        if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # wf_data_poitns sono il numero di punti in ogni waveform\n",
    "        # un altro modo per ottenere N_of_events sarebbe cercare la riga che contiene il numero di frames (\"FastFrame Count,1000\") e dividere il numero totale di righe per il numero di frames\n",
    "        \n",
    "        if line.startswith(\"TIME\"):\n",
    "            wf_table = pd.read_csv(wf_path, header = line_counter-1)            # creo il dataframe dei dati delle wf considerando come header tutte le righe fino a TIME\n",
    "            break                                                               # esco dal ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d9771f7-79e0-4fce-9fcb-e4a22f6a1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione di analisi per la ricerca dei minimi\n",
    "def analysis(timestamp_table, wf_table,wf_datapoints):\n",
    "# inizializzo un dataframe generale\n",
    "    general_min_list = []\n",
    "\n",
    "# cicla con un contatore che scorre su tutto il range lungo come il numero di eventi di trigger\n",
    "    for n in range(N_of_events):\n",
    "# end = '\\r' inserisce \\r alla fine della stringa, quindi riporta il puntatore all'inizio della riga in modo da sovrascrivere l'output precedente\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r')\n",
    "# nome del singolo evento analizzato in questa iterazione del ciclo\n",
    "# preparo già il nome con l'estensione giusta per quando stamperò l'immagine della waveform\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "# prima di estrarre i punti relativi alla singola waveform, convertiamo i tempi relativi in tempi assoluti\n",
    "# la colonna \"TIME\" contiene, per ogni waveform, i tempi relativi all'evento di trigger che ha avviato l'acquisizione della waveform\n",
    "# per convertire questi tempi relativi in tempi assoluti (o meglio relativi all'inizio della misura) dobbiamo aggiungere ai tempi di ogni waveform il corrispondente timestamp del trigger\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "\n",
    "# estraggo una singola waveform, ovvero 6250 punti, dalla tabella principale\n",
    "# single_wf è un DataFrame\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "\n",
    "# la funzione argrelextrema restituisce gli estremi relativi, calcolati in base all'operatore np.less_equal\n",
    "# aumentando l'ordine diminuiamo il numero di minimi trovati\n",
    "# Il range totale di punti viene suddiviso in intervalli di lunghezza proporzionale a \"order\", successivamente viene \n",
    "# estratto il minimo assoluto di ogni intervallo:\n",
    "# i minimi così trovati sono i minimi relativi restituiti dalla funzione argrelextrema\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "\n",
    "# la riga seguente serve per identificare i minimi ed inserirli nella singola waveform, in modo da vederli nei plot\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "\n",
    "# eseguo un fit di ordine 0 (quindi una media aritmetica) sui primi 250 punti, che rientrano nella zona di pre-trigger\n",
    "# (ovvero i punti precedenti all'evento di trigger), per determinare la baseline del segnale\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "# definisco una lista di minimi \"buoni\" da riempire in seguito\n",
    "        clean_minimum_list = []\n",
    "\n",
    "############################# Soglia scelta per bontà minimo ##################################\n",
    "# i minimi saranno considerati buoni se hanno ampiezza superiore a 0.006, rispetto alla baseline\n",
    "# e se hanno una distanza dall'indice precedente di almeno 50 dati\n",
    "        gap = 0.006 # mV\n",
    "        distance = 50\n",
    "###############################################################################################\n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "# un controllo sugli indici previene massimi vicini \n",
    "# (provate a togliere and (index > previous_index + 50) e vedete cosa succede)\n",
    "# se l'indice del minimo attuale dista dal suo precedente di almeno distance, allora appendo\n",
    "# l'indice del dato individuato come minimo \"buono\" alla lista clean_minimum_list\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "# aggiungo la colonna di minimi \"buoni\" alla tabella\n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "# l'indice corrispettivo sulla tabella principale è sfasato di un valore n*6250\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "\n",
    "            \n",
    "############################## PLOTTING ##############################################\n",
    "# le seguenti linee di comando servono per graficare le singole waveforms\n",
    "# !!!!!!!!! attenzione al numero di cicli nel for, altrimenti aprite 6250 grafici !!!!!!!!!\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "        plt.savefig(figure_path)\n",
    "        plt.close()\n",
    "        \n",
    "        ####################### Evitiamo disastri ##################################\n",
    "        break\n",
    "        ############################################################################\n",
    "        \n",
    "    print('Analisi completata!!                       ')\n",
    "    return general_min_list\n",
    "\n",
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop",
   "language": "python",
   "name": "oop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
