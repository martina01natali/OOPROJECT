{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d11171-dc97-4f4f-b0e7-d70389009d05",
   "metadata": {},
   "source": [
    "# DCR analysis\n",
    "\n",
    "## Processing of waveforms\n",
    "\n",
    "**GOAL**\n",
    "- count all events\n",
    "- make plot amplitude VS time to discriminate between 1 phe signals (\"real counts\" and afterpulses) and 2 phe signals (crosstalks)\n",
    "- evaluate % of afterpulses and crosstalks wrt total\n",
    "\n",
    "Notes: time axis has a physical minimum due to width of waveform\n",
    "\n",
    "**Procedure**\n",
    "- csv files of waveforms and timestamps combined\n",
    "- csv files, sliced into single waveforms\n",
    "- find minima (absolute and relative), plot them, count them (count single points of absolute minimum) and save their timestamps and amplitude\n",
    "- from amplitude value you understand if a peak is noise (crosstalk, afterpulse)\n",
    "- get amplitudes and timestamps of each minimum\n",
    "\n",
    "*Afterpulse*: happens tipically at 0.5 $\\mu$s after a real signal, and has an amplitude almost equal to 1 phe; threshold for considering an event an afterpulse of the event before is 6 $\\mu$s.  \n",
    "*Crosstalk*: single peak of amplitude 2 phe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea419a-779a-433e-a335-d8c3d6a749ba",
   "metadata": {},
   "source": [
    "## Goals, tips and tricks\n",
    "\n",
    "You have to find an automated way to find the \"good\" absolute minimum.\n",
    "How?\n",
    "\n",
    "- [x] Extrapolate baseline: evaluate it by using only pre-trigger amplitudes.\n",
    "- [ ] **Raise an error or quarantine the snippet if you have a number of minima that is too big**\n",
    "- [ ] **Evaluate the derivative of the ramp up of a peak**\n",
    "- [ ] Dark count rate is number of total events / total time --> **calculate total time**\n",
    "- [x] Discriminate if two peaks have a distance between each other that is too small (is less than the width of the window)\n",
    "\n",
    "Options to follow to throw away noisy signals:\n",
    "\n",
    "1. Throw away all noise: if the waveform is not good (has more than one minimum that goes over the threshold) throw it away completely; have to count all the waveforms that are thrown and estimate fraction of total events\n",
    "2. Check on saturated events: must be true to have points over the threshold and also have some number of points (like, 10) in a very narrow range of values (all equal)\n",
    "\n",
    "Final goals:\n",
    "\n",
    "1. Create 2D plot with time deltas (x) and amplitude (y): time deltas are the differences between timestamps of any two successive \"good\" peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520b95e-471f-4eb7-93fc-80b6b4612840",
   "metadata": {},
   "source": [
    "### Code from Guarise\n",
    "\n",
    "Already commented by Guarise, I already reviewed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7dfe734-082f-4572-8779-32484e15ccd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# timestamp_file_name è il path relativo del file di dati a partire dalla cwd\n",
    "timestamp_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\"             # nome del file con i timestamp del trigger\n",
    "\n",
    "# definisco l'indirizzo, os.path.join() unisce un indirizzo base al nome di un file specifico\n",
    "timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)                  # getcwd() restituisce l'indirizzo della cartella nella quale è contenuto questo programma\n",
    "\n",
    "timestamp_table = pd.read_csv(timestamp_path)                                   # leggo i dati relativi ai timestamp del trigger, disponendoli in un dataframe\n",
    "                                                                                # timestamp_table.head(10) per visualizzare i dati ottenuti\n",
    "\n",
    "\n",
    "# rinomino le colonne, Event è un indice che va da 1 a 1000 (numero di eventi), mentre Delta T è il tempo trascorso dal trigger precedente\n",
    "timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "N_of_events = len(timestamp_table)                                              # Numero di waveforms (o eventi), che corrisponde al numero di eventi di trigger\n",
    "# .diff effettua la somma cumulativa di ogni riga con quelle precedente\n",
    "timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)      # axis identifica l'asse, se lungo le righe (0) o lungo le colonne (1)\n",
    "wf_data_points = 0                                                              # inizializzo la variabile wf_data_point che corrisponde al numero di punti in ogni waveform (6250)\n",
    "\n",
    "# definisco il nome del file con i dati delle waveforms, questi dati sono posti in modo contiguo ovvero in un unico file csv\n",
    "# dividendo le righe in gruppi da 6250 elementi possiamo ottenere le singole waveforms\n",
    "wf_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\"                                    \n",
    "wf_path = os.path.join(os.getcwd(),wf_file_name)                                \n",
    "wf_table = pd.DataFrame()                                                       \n",
    "\n",
    "with open(wf_file_name, 'r') as file_wf:                                        # apro il file e inserisco le righe in una lista\n",
    "    lines = file_wf.readlines()\n",
    "    for line_counter, line in enumerate(lines):                                 # cerco la riga che inizia per TIME ma prima cerco Record Lenght per ottenere il valore di wf_data_point\n",
    "        if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # wf_data_poitns sono il numero di punti in ogni waveform\n",
    "        # un altro modo per ottenere N_of_events sarebbe cercare la riga che contiene il numero di frames (\"FastFrame Count,1000\") e dividere il numero totale di righe per il numero di frames\n",
    "        \n",
    "        if line.startswith(\"TIME\"):\n",
    "            wf_table = pd.read_csv(wf_path, header = line_counter-1)            # creo il dataframe dei dati delle wf considerando come header tutte le righe fino a TIME\n",
    "            break                                                               # esco dal ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42bf6fd3-5475-4b62-a2c9-5d8631bd3dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metodo usato a lezione (meno elegante ma funziona comunque, riportato giusto per completezza)\n",
    "# line_counter = 0\n",
    "# n_line = -1\n",
    "# while n_line == -1:\n",
    "#     line = waveform_file.readline()\n",
    "#     line_counter += 1\n",
    "#     if line_counter == 100:\n",
    "#         print(\"ERROR\")\n",
    "# waveform_table = pd.read_csv(\"HPKR00030_2cicli_OV3_wf.csv\", header = n_line-1)\n",
    "\n",
    "# il metodo per il calcolo dei timestamp, allo stesso modo, è più elegante di quello trattato a lezione, che riporto qui sotto per completezza\n",
    "# timestamp_table.at[0,'Timestamp'] = timestamp_table.iloc[0]['Delta T']\n",
    "# for i in timestamp_table.index[1:]:\n",
    "#     timestamp_table.at[i,\"Timestamp\"] = timestamp_table.at[i-1,\"Timestamp\"] + timestamp_table.at[i,\"Delta T\"]\n",
    "\n",
    "# funzione di analisi per la ricerca dei minimi\n",
    "def analysis(timestamp_table, wf_table,wf_datapoints):\n",
    "# inizializzo un dataframe generale\n",
    "    general_min_list = []\n",
    "\n",
    "# cicla con un contatore che scorre su tutto il range lungo come il numero di eventi di trigger\n",
    "    for n in range(N_of_events):\n",
    "# end = '\\r' inserisce \\r alla fine della stringa, quindi riporta il puntatore all'inizio della riga in modo da sovrascrivere l'output precedente\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r')\n",
    "# nome del singolo evento analizzato in questa iterazione del ciclo\n",
    "# preparo già il nome con l'estensione giusta per quando stamperò l'immagine della waveform\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "# prima di estrarre i punti relativi alla singola waveform, convertiamo i tempi relativi in tempi assoluti\n",
    "# la colonna \"TIME\" contiene, per ogni waveform, i tempi relativi all'evento di trigger che ha avviato l'acquisizione della waveform\n",
    "# per convertire questi tempi relativi in tempi assoluti (o meglio relativi all'inizio della misura) dobbiamo aggiungere ai tempi di ogni waveform il corrispondente timestamp del trigger\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "\n",
    "# estraggo una singola waveform, ovvero 6250 punti, dalla tabella principale\n",
    "# single_wf è un DataFrame\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "\n",
    "# la funzione argrelextrema restituisce gli estremi relativi, calcolati in base all'operatore np.less_equal\n",
    "# aumentando l'ordine diminuiamo il numero di minimi trovati\n",
    "# Il range totale di punti viene suddiviso in intervalli di lunghezza proporzionale a \"order\", successivamente viene \n",
    "# estratto il minimo assoluto di ogni intervallo:\n",
    "# i minimi così trovati sono i minimi relativi restituiti dalla funzione argrelextrema\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "\n",
    "# la riga seguente serve per identificare i minimi ed inserirli nella singola waveform, in modo da vederli nei plot\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "\n",
    "# eseguo un fit di ordine 0 (quindi una media aritmetica) sui primi 250 punti, che rientrano nella zona di pre-trigger\n",
    "# (ovvero i punti precedenti all'evento di trigger), per determinare la baseline del segnale\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "# definisco una lista di minimi \"buoni\" da riempire in seguito\n",
    "        clean_minimum_list = []\n",
    "\n",
    "############################# Soglia scelta per bontà minimo ##################################\n",
    "# i minimi saranno considerati buoni se hanno ampiezza superiore a 0.006, rispetto alla baseline\n",
    "# e se hanno una distanza dall'indice precedente di almeno 50 dati\n",
    "        gap = 0.006 # mV\n",
    "        distance = 50\n",
    "###############################################################################################\n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "# un controllo sugli indici previene massimi vicini \n",
    "# (provate a togliere and (index > previous_index + 50) e vedete cosa succede)\n",
    "# se l'indice del minimo attuale dista dal suo precedente di almeno distance, allora appendo\n",
    "# l'indice del dato individuato come minimo \"buono\" alla lista clean_minimum_list\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "# aggiungo la colonna di minimi \"buoni\" alla tabella\n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "# l'indice corrispettivo sulla tabella principale è sfasato di un valore n*6250\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "\n",
    "# le seguenti linee di comando servono per graficare le singole waveforms\n",
    "# !!!!!!!!! attenzione al numero di cicli nel for, altrimenti aprite 6250 grafici !!!!!!!!!\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "        plt.savefig(figure_path)\n",
    "        plt.close()\n",
    "        \n",
    "        ####################### Evitiamo disastri ##################################\n",
    "        break\n",
    "        ############################################################################\n",
    "        \n",
    "    print('Analisi completata!!                       ')\n",
    "    return general_min_list\n",
    "\n",
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ac2ff-870f-4cf7-a433-22a2038ab205",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### My code structure\n",
    "\n",
    "Starting from code from Guarise, polishing and dividing in different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6289bb-5c4d-4abc-b912-7a316d36e7b8",
   "metadata": {},
   "source": [
    "**Header**\n",
    "```python\n",
    "\n",
    "def read_wf(file_name):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf detection from file_name;\n",
    "    also constructs both dataframes\n",
    "    \"\"\"\n",
    "    if file name contains 'time.csv' then do...\n",
    "    if else file_name contains wf.csv then do...\n",
    "    else NameError\n",
    "        raise\n",
    "\n",
    "def analysis_wf(timestamp_table, wf_table, wf_datapoints, threshold, distance, inplace=True):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (mV)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    \n",
    "def plot_wf(timestamp_table, wf_table, wf_datapoints, loop=True, show=False, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(mV) vs timestamp plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing.\n",
    "    \"\"\"\n",
    "\n",
    "def plot_dcr(minimum_table, hist=True):\n",
    "    \"\"\"\n",
    "    Only needs a dataframe minimum_table with the list of the minima and the related timestamps.\n",
    "    Plots an amplitude (mV) vs delta_t (ns) graph, useful to detect noise source.\n",
    "    Option hist=True plots an histogram subplot under the 2D plot, representing the integral in the vertical\n",
    "    direction of the ampli vs dt plot.\n",
    "    \"\"\"\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "256b9cf8-9082-41d9-a612-147baed5fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83f6d5fc-d1c0-4d41-ab4c-5cd834611641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dcr_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2e72f-8d6c-4892-8d01-578f6862d437",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "752c597c-4983-4c03-bcd9-eabf23c1b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wf(fname):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf file type detection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - fname: relative path of the file with respect to the current working directory\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas' dataframe of the data provided.\n",
    "    \n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - requires both files, one after the other and detects which one is still missing \n",
    "        after the first is provided\n",
    "    - checks if they refer to the same data taking (from the path itself)\n",
    "    \n",
    "    #################################################################################\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # If the file provided is a timestamp file, follow this routine:\n",
    "    # - open the file\n",
    "    # - make a dataframe with the timestamps; the header is as default in line 0\n",
    "    # - timestamps are relative and provide the time interval with respect to the previous trigger:\n",
    "    #    make them absolute by computing the cumulative of each timestamp with cumsum method of pd\n",
    "    if re.search(\"time.csv\", fname): \n",
    "        timestamp_file_name = fname\n",
    "        timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)\n",
    "        timestamp_table = pd.read_csv(timestamp_path) \n",
    "            # if file is not found, FileNotFoundError is raised automatically\n",
    "        timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "        N_of_events = len(timestamp_table) # = 1000\n",
    "        timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)\n",
    "        \n",
    "        return timestamp_table\n",
    "        \n",
    "    # If the file provided is a waveform file, follow this routine:\n",
    "    # - open the file\n",
    "    # - detect the number of datapoints in each waveform, wf_datapoints = 6250\n",
    "    # - detect end of header (\"TIME\") and make a dataframe with the wf data\n",
    "    elif re.search(\"wf.csv\", fname):\n",
    "        wf_file_name = fname\n",
    "        wf_path = os.path.join(os.getcwd(),wf_file_name)\n",
    "        wf_table = pd.DataFrame()\n",
    "        \n",
    "        with open(wf_file_name, 'r') as file_wf:\n",
    "                # if file is not found, FileNotFoundError is raised automatically\n",
    "            lines = file_wf.readlines()\n",
    "            for line_counter, line in enumerate(lines):\n",
    "                if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # = 6250\n",
    "                if line.startswith(\"Horizontal\"): time_unit = str(line.split(',')[-1]).rstrip(\"\\n\") # = s\\n\n",
    "                if line.startswith(\"Vertical\"): ampl_unit = str(line.split(',')[-1]).rstrip(\"\\n\") # = V\\n\n",
    "                if line.startswith(\"FastFrame\"): wf_events = int(line.split(',')[-1]) # = 1000\n",
    "                    # To implement when both files are required by the function\n",
    "                    # if wf_events != N_of_events: break\n",
    "                if line.startswith(\"TIME\"):\n",
    "                    wf_table = pd.read_csv(wf_path, header = line_counter-1)\n",
    "                    break\n",
    "        \n",
    "        meta = pd.DataFrame.from_dict({\n",
    "            'path' : wf_path,\n",
    "            'n events' : wf_events,\n",
    "            'data points' : wf_datapoints,\n",
    "            'time units' : time_unit,\n",
    "            'ampl units' : ampl_unit,\n",
    "        }, orient='index')\n",
    "                    \n",
    "        return wf_table, meta\n",
    "    \n",
    "    else:\n",
    "        raise NameError(\"Please provide the path to a waveform or timestamp comma-separated file (.csv).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d170e5c-8250-41a1-b229-60734dea95e7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1b868698-c127-4072-b0b4-08bf71fed497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(timestamp_table, wf_table, custom_n_events=1000, inplace=False,\n",
    "             threshold=0.006, distance=50,\n",
    "             plot=False, save_plot=False):\n",
    "    \"\"\"Function to analyze waveform data and locate clean signal peaks.\n",
    "    \n",
    "    This function finds all the minima in each waveform and selects the \"good ones\" based on the values\n",
    "    of threshold (V) and distance.\n",
    "   \n",
    "   ------\n",
    "   Input:\n",
    "   - timestamp_table: pandas.DataFrame\n",
    "       Dataframe with timestamps\n",
    "   - wf_table: pandas.DataFrame\n",
    "       Dataframe with waveforms in list mode\n",
    "   - custom_n_events: int, deafult 1000\n",
    "       Number of events to analyze (starts from the first waveform in any case)\n",
    "   - inplace: bbol, default False\n",
    "       If True, modifies the input dataframe wf_table. If False, returns a copy.\n",
    "   - threshold: float, default 0.006 [V]\n",
    "       Minimum value of signal to discriminate it from noise, in units of V\n",
    "   - distance: int, default 50\n",
    "       Number of data in between two consecutive absolute minima\n",
    "   - plot: bool, default False\n",
    "       If True, plot the scatterplot of the waveforms with the relative minima in a\n",
    "       recursive way\n",
    "   \n",
    "   --------\n",
    "   Returns:\n",
    "   - copy of original dataframe with added columns of minima (total) and clean minima (based\n",
    "       on threshold and distance)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ############################# UPDATES TO MAKE ####################################\n",
    "    # - [x] RETURNS wf_table complete with all clean minima\n",
    "    # - [x] MUST HAVE inplace=True/False option: like this you're rewriting wf_table every time\n",
    "    # - [x] must decide if you want or not to be able to plot relative minima\n",
    "    # - [ ] option to discard waveforms with more than ...how many are too much? relative minima\n",
    "    #     - [ ] count # of discarded waveforms and get fraction wrt total \n",
    "    # - [ ] discard saturated waveforms: must have a lot of almost-same-amplitude points \n",
    "    # \n",
    "    #\n",
    "    ##################################################################################\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    N_of_events = custom_n_events        \n",
    "    wf_datapoints = wf_table.iloc[:,0].size/1000\n",
    "    \n",
    "    general_clean_min = []\n",
    "    N_bad_wf = 0\n",
    "    \n",
    "    for n in range(N_of_events):\n",
    "        print(\"Analysis of event number \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        \n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "        \n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy() #(deep=False)\n",
    "        \n",
    "        # Find minima\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = distance)[0]\n",
    "        \n",
    "    ############################# UPDATE ####################################\n",
    "    # - [ ] identify waveforms with too many minima\n",
    "    # - [ ] Add tag \"bad\" along with minimum list, to be added as column in final, total df\n",
    "\n",
    "        if len(minimum_list) > 100:\n",
    "            N_bad_wf += 1\n",
    "            # continue\n",
    "        \n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        gap = threshold\n",
    "        distance = distance\n",
    "        \n",
    "        clean_minimum_list = []\n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_clean_min.append(index + wf_index)\n",
    "            \n",
    "        if plot==True:\n",
    "            plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "            plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "            plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "            plt.axhline(baseline, c='b')\n",
    "            plt.show()\n",
    "            \n",
    "            if save_plot==True:\n",
    "                figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "                plt.savefig(figure_path)\n",
    "            \n",
    "            plt.close()\n",
    "    \n",
    "    print('\\nAnalysis completed.')\n",
    "    print('Fraction of noisy waveforms on total: %s%%' % format(N_bad_wf/custom_n_events*100,\".2f\"))\n",
    "    print(\"Process completed in %s s.\" % (format(time.time()-start_time,\".2f\")))\n",
    "    \n",
    "    if inplace==True:\n",
    "        wf_table.loc[:,'clean_min'] = wf_table.loc[general_clean_min]['CH1']\n",
    "        return wf_table\n",
    "    else:\n",
    "        copy = wf_table.copy()\n",
    "        copy.loc[:,'clean_min'] = copy.loc[general_clean_min]['CH1']\n",
    "        return copy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10d6978c-8299-47b9-a45f-ab539727c8b7",
   "metadata": {},
   "source": [
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3331e8-c698-4834-8b6b-9993e855dd0e",
   "metadata": {},
   "source": [
    "## Plot scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3966d7ea-02a1-4a06-a9fe-b670db600e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## PLOTTING ##############################################\n",
    "def plot_wf(wf_table, N_of_events=1000, loop=False, show=True, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(V) vs timestamp(s) plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing, and shows the plot.\n",
    "\n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - see if this works :)\n",
    "    #################################################################################\n",
    "    \"\"\"\n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        wf_datapoints = wf_table.iloc[:,0].size/N_of_events\n",
    "        \n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        # plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        \n",
    "        if save==True:\n",
    "            figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "            plt.savefig(figure_path)\n",
    "\n",
    "        if show==True:\n",
    "            plt.show()\n",
    "            \n",
    "        plt.close()\n",
    "    \n",
    "        if loop!=True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e6bb2-739e-4ad5-bbba-6ffbedce6267",
   "metadata": {},
   "source": [
    "## Plot 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d2b92d-efef-4a6c-9c85-c0ffa26409ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0743b-9256-405e-895d-114a1e6b17bb",
   "metadata": {},
   "source": [
    "# Blocks for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a30ae291-8c98-4b4b-a7a1-94fdbacb45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_table, meta = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f90ef4-d097-4860-8cd9-209a39513321",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>C:\\Users\\MARTINA\\Desktop\\OOPROJECT\\pyproj\\bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n events</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data points</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time units</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl units</th>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             0\n",
       "path         C:\\Users\\MARTINA\\Desktop\\OOPROJECT\\pyproj\\bran...\n",
       "n events                                                  1000\n",
       "data points                                               6250\n",
       "time units                                                   s\n",
       "ampl units                                                   V"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7bc91e6e-ecfa-46a8-8184-23f0dc106e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f5f12f0-e5f6-4026-96a6-cb0080bee5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.962500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.930500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME       CH1\n",
       "0 -9.994500e-08 -0.000809\n",
       "1 -9.978500e-08 -0.000809\n",
       "2 -9.962500e-08 -0.000809\n",
       "3 -9.946500e-08 -0.000809\n",
       "4 -9.930500e-08 -0.000809"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "86e57ff7-3228-4ae2-9ec1-7971e9c0c85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.015771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.020706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event  Timestamp\n",
       "0      0   0.000000\n",
       "1      1   0.015416\n",
       "2      2   0.015771\n",
       "3      3   0.020706\n",
       "4      4   0.030981"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f270e400-bb15-42e7-92b8-ed6fe6b6d316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of event number 9\n",
      "Analysis completed.\n",
      "Fraction of noisy waveforms on total: 100.00%\n",
      "Process completed in 0.29 s.\n"
     ]
    }
   ],
   "source": [
    "ten_wf = analysis(time_table, wf_table, custom_n_events=10, plot=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ccd972d6-f1e6-43d5-bff9-4ddc9143aca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "      <th>clean_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.962500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.930500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME       CH1  clean_min\n",
       "0 -9.994500e-08 -0.000809        NaN\n",
       "1 -9.978500e-08 -0.000809        NaN\n",
       "2 -9.962500e-08 -0.000809        NaN\n",
       "3 -9.946500e-08 -0.000809        NaN\n",
       "4 -9.930500e-08 -0.000809        NaN"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_wf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76497ab6-97e8-4932-8c66-e846a4ba7e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TIME       CH1\n",
       "0 -9.994500e-08 -0.000809\n",
       "1 -9.978500e-08 -0.000809"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova.append(wf_table.iloc[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d8a0d4f5-740c-4e41-a756-31959ac9f18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d28bec3a-d269-4594-b041-494643aabbc7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "############################### COMMENTED VERSION ###################################\n",
    "\n",
    "def analysis(timestamp_table, wf_table, threshold=0.006, distance=50,\n",
    "            inplace=False):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (V)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    # Get number of events and number of points in each waveform\n",
    "    N_of_events = time_table.iloc[:,0].size\n",
    "    wf_datapoints = wf_table.iloc[:,0].size/N_of_events\n",
    "    \n",
    "    # There are 1000 events: each event is a single waveform, containing 6250 points.\n",
    "    # Pre-trigger signal is present: length of 250 data\n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "    # Conversion from relative times to absolute: timestamps of points of the waveform are summed to\n",
    "    # their relative trigger timestamp from timestamp_table\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "        \n",
    "    # Take a single waveform at a time\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        \n",
    "    # Make the list of the indexes of the relative minima in the waveform\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "    # Add list of minima to main dataframe\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "    # Compute baseline as average of first 250 wf datapoints, that constitute the pre-trigger region \n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        clean_minimum_list = []\n",
    "\n",
    "    # Define threshold for relative minimum to be considered good signal,\n",
    "    # and its minimum relative distance with respect to the prior minimum\n",
    "        gap = threshold # default = 50\n",
    "        distance = distance # default = 50 \n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        general_min_list = []\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "            \n",
    "    return single_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bf3047ae-a707-4815-9357-d754cc4fd475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table.iloc[:,0].size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop",
   "language": "python",
   "name": "oop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
