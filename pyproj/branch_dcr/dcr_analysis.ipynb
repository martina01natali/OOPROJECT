{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d11171-dc97-4f4f-b0e7-d70389009d05",
   "metadata": {},
   "source": [
    "# DCR analysis\n",
    "\n",
    "## Processing of waveforms\n",
    "\n",
    "**GOAL**\n",
    "- count all events\n",
    "- make plot amplitude VS time to discriminate between 1 phe signals (\"real counts\" and afterpulses) and 2 phe signals (crosstalks)\n",
    "- evaluate % of afterpulses and crosstalks wrt total\n",
    "\n",
    "Notes: time axis has a physical minimum due to width of waveform\n",
    "\n",
    "**Procedure**\n",
    "- csv files of waveforms and timestamps combined\n",
    "- csv files, sliced into single waveforms\n",
    "- find minima (absolute and relative), plot them, count them (count single points of absolute minimum) and save their timestamps and amplitude\n",
    "- from amplitude value you understand if a peak is noise (crosstalk, afterpulse)\n",
    "- get amplitudes and timestamps of each minimum\n",
    "\n",
    "*Afterpulse*: happens tipically at 0.5 $\\mu$s after a real signal, and has an amplitude almost equal to 1 phe; threshold for considering an event an afterpulse of the event before is 6 $\\mu$s.  \n",
    "*Crosstalk*: single peak of amplitude 2 phe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520b95e-471f-4eb7-93fc-80b6b4612840",
   "metadata": {},
   "source": [
    "### Code from Guarise\n",
    "\n",
    "Already commented by Guarise and me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7dfe734-082f-4572-8779-32484e15ccd3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# timestamp_file_name è il path relativo del file di dati a partire dalla cwd\n",
    "timestamp_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\"             # nome del file con i timestamp del trigger\n",
    "\n",
    "# definisco l'indirizzo, os.path.join() unisce un indirizzo base al nome di un file specifico\n",
    "timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)                  # getcwd() restituisce l'indirizzo della cartella nella quale è contenuto questo programma\n",
    "\n",
    "timestamp_table = pd.read_csv(timestamp_path)                                   # leggo i dati relativi ai timestamp del trigger, disponendoli in un dataframe\n",
    "                                                                                # timestamp_table.head(10) per visualizzare i dati ottenuti\n",
    "\n",
    "\n",
    "# rinomino le colonne, Event è un indice che va da 1 a 1000 (numero di eventi), mentre Delta T è il tempo trascorso dal trigger precedente\n",
    "timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "N_of_events = len(timestamp_table)                                              # Numero di waveforms (o eventi), che corrisponde al numero di eventi di trigger\n",
    "# .diff effettua la somma cumulativa di ogni riga con quelle precedente\n",
    "timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)      # axis identifica l'asse, se lungo le righe (0) o lungo le colonne (1)\n",
    "wf_data_points = 0                                                              # inizializzo la variabile wf_data_point che corrisponde al numero di punti in ogni waveform (6250)\n",
    "\n",
    "# definisco il nome del file con i dati delle waveforms, questi dati sono posti in modo contiguo ovvero in un unico file csv\n",
    "# dividendo le righe in gruppi da 6250 elementi possiamo ottenere le singole waveforms\n",
    "wf_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\"                                    \n",
    "wf_path = os.path.join(os.getcwd(),wf_file_name)                                \n",
    "wf_table = pd.DataFrame()                                                       \n",
    "\n",
    "with open(wf_file_name, 'r') as file_wf:                                        # apro il file e inserisco le righe in una lista\n",
    "    lines = file_wf.readlines()\n",
    "    for line_counter, line in enumerate(lines):                                 # cerco la riga che inizia per TIME ma prima cerco Record Lenght per ottenere il valore di wf_data_point\n",
    "        if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # wf_data_poitns sono il numero di punti in ogni waveform\n",
    "        # un altro modo per ottenere N_of_events sarebbe cercare la riga che contiene il numero di frames (\"FastFrame Count,1000\") e dividere il numero totale di righe per il numero di frames\n",
    "        \n",
    "        if line.startswith(\"TIME\"):\n",
    "            wf_table = pd.read_csv(wf_path, header = line_counter-1)            # creo il dataframe dei dati delle wf considerando come header tutte le righe fino a TIME\n",
    "            break                                                               # esco dal ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42bf6fd3-5475-4b62-a2c9-5d8631bd3dc9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# metodo usato a lezione (meno elegante ma funziona comunque, riportato giusto per completezza)\n",
    "# line_counter = 0\n",
    "# n_line = -1\n",
    "# while n_line == -1:\n",
    "#     line = waveform_file.readline()\n",
    "#     line_counter += 1\n",
    "#     if line_counter == 100:\n",
    "#         print(\"ERROR\")\n",
    "# waveform_table = pd.read_csv(\"HPKR00030_2cicli_OV3_wf.csv\", header = n_line-1)\n",
    "\n",
    "# il metodo per il calcolo dei timestamp, allo stesso modo, è più elegante di quello trattato a lezione, che riporto qui sotto per completezza\n",
    "# timestamp_table.at[0,'Timestamp'] = timestamp_table.iloc[0]['Delta T']\n",
    "# for i in timestamp_table.index[1:]:\n",
    "#     timestamp_table.at[i,\"Timestamp\"] = timestamp_table.at[i-1,\"Timestamp\"] + timestamp_table.at[i,\"Delta T\"]\n",
    "\n",
    "# funzione di analisi per la ricerca dei minimi\n",
    "def analysis(timestamp_table, wf_table,wf_datapoints):\n",
    "# inizializzo un dataframe generale\n",
    "    general_min_list = []\n",
    "\n",
    "# cicla con un contatore che scorre su tutto il range lungo come il numero di eventi di trigger\n",
    "    for n in range(N_of_events):\n",
    "# end = '\\r' inserisce \\r alla fine della stringa, quindi riporta il puntatore all'inizio della riga in modo da sovrascrivere l'output precedente\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r')\n",
    "# nome del singolo evento analizzato in questa iterazione del ciclo\n",
    "# preparo già il nome con l'estensione giusta per quando stamperò l'immagine della waveform\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "# prima di estrarre i punti relativi alla singola waveform, convertiamo i tempi relativi in tempi assoluti\n",
    "# la colonna \"TIME\" contiene, per ogni waveform, i tempi relativi all'evento di trigger che ha avviato l'acquisizione della waveform\n",
    "# per convertire questi tempi relativi in tempi assoluti (o meglio relativi all'inizio della misura) dobbiamo aggiungere ai tempi di ogni waveform il corrispondente timestamp del trigger\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "\n",
    "# estraggo una singola waveform, ovvero 6250 punti, dalla tabella principale\n",
    "# single_wf è un DataFrame\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "\n",
    "# la funzione argrelextrema restituisce gli estremi relativi, calcolati in base all'operatore np.less_equal\n",
    "# aumentando l'ordine diminuiamo il numero di minimi trovati\n",
    "# Il range totale di punti viene suddiviso in intervalli di lunghezza proporzionale a \"order\", successivamente viene \n",
    "# estratto il minimo assoluto di ogni intervallo:\n",
    "# i minimi così trovati sono i minimi relativi restituiti dalla funzione argrelextrema\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "\n",
    "# la riga seguente serve per identificare i minimi ed inserirli nella singola waveform, in modo da vederli nei plot\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "\n",
    "# eseguo un fit di ordine 0 (quindi una media aritmetica) sui primi 250 punti, che rientrano nella zona di pre-trigger\n",
    "# (ovvero i punti precedenti all'evento di trigger), per determinare la baseline del segnale\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "# definisco una lista di minimi \"buoni\" da riempire in seguito\n",
    "        clean_minimum_list = []\n",
    "\n",
    "############################# Soglia scelta per bontà minimo ##################################\n",
    "# i minimi saranno considerati buoni se hanno ampiezza superiore a 0.006, rispetto alla baseline\n",
    "# e se hanno una distanza dall'indice precedente di almeno 50 dati\n",
    "        gap = 0.006 # mV\n",
    "        distance = 50\n",
    "###############################################################################################\n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "# un controllo sugli indici previene massimi vicini \n",
    "# (provate a togliere and (index > previous_index + 50) e vedete cosa succede)\n",
    "# se l'indice del minimo attuale dista dal suo precedente di almeno distance, allora appendo\n",
    "# l'indice del dato individuato come minimo \"buono\" alla lista clean_minimum_list\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "# aggiungo la colonna di minimi \"buoni\" alla tabella\n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "# l'indice corrispettivo sulla tabella principale è sfasato di un valore n*6250\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "\n",
    "# le seguenti linee di comando servono per graficare le singole waveforms\n",
    "# !!!!!!!!! attenzione al numero di cicli nel for, altrimenti aprite 6250 grafici !!!!!!!!!\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "        plt.savefig(figure_path)\n",
    "        plt.close()\n",
    "        \n",
    "        ####################### Evitiamo disastri ##################################\n",
    "        break\n",
    "        ############################################################################\n",
    "        \n",
    "    print('Analisi completata!!                       ')\n",
    "    return general_min_list\n",
    "\n",
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ac2ff-870f-4cf7-a433-22a2038ab205",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### My code\n",
    "\n",
    "Starting from code from Guarise, polishing and dividing in different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6289bb-5c4d-4abc-b912-7a316d36e7b8",
   "metadata": {},
   "source": [
    "**Header**\n",
    "```python\n",
    "\n",
    "def read_wf(file_name):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf detection from file_name;\n",
    "    also constructs both dataframes\n",
    "    \"\"\"\n",
    "    if file name contains 'time.csv' then do...\n",
    "    if else file_name contains wf.csv then do...\n",
    "    else NameError\n",
    "        raise\n",
    "\n",
    "def analysis_wf(timestamp_table, wf_table, wf_datapoints, threshold, distance, inplace=True):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (mV)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    \n",
    "def plot_wf(timestamp_table, wf_table, wf_datapoints, loop=True, show=False, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(mV) vs timestamp plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing.\n",
    "    \"\"\"\n",
    "\n",
    "def plot_dcr(minimum_table, hist=True):\n",
    "    \"\"\"\n",
    "    Only needs a dataframe minimum_table with the list of the minima and the related timestamps.\n",
    "    Plots an amplitude (mV) vs delta_t (ns) graph, useful to detect noise source.\n",
    "    Option hist=True plots an histogram subplot under the 2D plot, representing the integral in the vertical\n",
    "    direction of the ampli vs dt plot.\n",
    "    \"\"\"\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "256b9cf8-9082-41d9-a612-147baed5fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6a86e89-35d7-4093-8faf-6a2751c1b859",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_wf(fname):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf file type detection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - fname: relative path of the file with respect to the current working directory\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas' dataframe of the data provided.\n",
    "    \n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - requires both files, one after the other and detects which one is still missing \n",
    "        after the first is provided\n",
    "    - checks if they refer to the same data taking (from the path itself)\n",
    "    \n",
    "    #################################################################################\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    # If the file provided is a timestamp file, follow this routine:\n",
    "    # - open the file\n",
    "    # - make a dataframe with the timestamps; the header is as default in line 0\n",
    "    # - timestamps are relative and provide the time interval with respect to the previous trigger:\n",
    "    #    make them absolute by computing the cumulative of each timestamp with cumsum method of pd\n",
    "    if re.search(\"time.csv\", fname): \n",
    "        timestamp_file_name = fname\n",
    "        timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)\n",
    "        timestamp_table = pd.read_csv(timestamp_path) \n",
    "            # if file is not found, FileNotFoundError is raised automatically\n",
    "        timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "        N_of_events = len(timestamp_table) # = 1000\n",
    "        timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)\n",
    "        \n",
    "        return timestamp_table\n",
    "        \n",
    "    # If the file provided is a waveform file, follow this routine:\n",
    "    # - open the file\n",
    "    # - detect the number of datapoints in each waveform, wf_datapoints = 6250\n",
    "    # - detect end of header (\"TIME\") and make a dataframe with the wf data\n",
    "    elif re.search(\"wf.csv\", fname):\n",
    "        wf_file_name = fname\n",
    "        wf_path = os.path.join(os.getcwd(),wf_file_name)\n",
    "        wf_table = pd.DataFrame()\n",
    "        \n",
    "        with open(wf_file_name, 'r') as file_wf:\n",
    "                # if file is not found, FileNotFoundError is raised automatically\n",
    "            lines = file_wf.readlines()\n",
    "            for line_counter, line in enumerate(lines):\n",
    "                if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # = 6250\n",
    "                if line.startswith(\"Horizontal\"): time_unit = str(line.split(',')[-1]) # = s\n",
    "                if line.startswith(\"Vertical\"): ampl_unit = str(line.split(',')[-1]) # = V\n",
    "                if line.startswith(\"FastFrame\"): wf_events = int(line.split(',')[-1]) # = 1000\n",
    "                    # To implement when both files are required by the function\n",
    "                    # if wf_events != N_of_events: break\n",
    "                if line.startswith(\"TIME\"):\n",
    "                    wf_table = pd.read_csv(wf_path, header = line_counter-1)\n",
    "                    break\n",
    "        \n",
    "        meta = pd.DataFrame.from_dict({\n",
    "            'path' : wf_path,\n",
    "            'n events' : wf_events,\n",
    "            'data points' : wf_datapoints,\n",
    "            'time units' : time_unit, # splitting the string by '\\' or '\\\\' doesn't make it detect the '\\n' char\n",
    "            'ampl units' : ampl_unit,\n",
    "        }, orient='index')\n",
    "                    \n",
    "        return wf_table, meta\n",
    "    \n",
    "    else:\n",
    "        raise NameError(\"Please provide the path to a waveform or timestamp comma-separated file (.csv).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a30ae291-8c98-4b4b-a7a1-94fdbacb45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_table, meta = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7bc91e6e-ecfa-46a8-8184-23f0dc106e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3f5f12f0-e5f6-4026-96a6-cb0080bee5ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.962500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.930500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249995</th>\n",
       "      <td>8.993500e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249996</th>\n",
       "      <td>8.995100e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249997</th>\n",
       "      <td>8.996700e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249998</th>\n",
       "      <td>8.998300e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249999</th>\n",
       "      <td>8.999900e-07</td>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TIME       CH1\n",
       "0       -9.994500e-08 -0.000809\n",
       "1       -9.978500e-08 -0.000809\n",
       "2       -9.962500e-08 -0.000809\n",
       "3       -9.946500e-08 -0.000809\n",
       "4       -9.930500e-08 -0.000809\n",
       "...               ...       ...\n",
       "6249995  8.993500e-07 -0.000496\n",
       "6249996  8.995100e-07 -0.000496\n",
       "6249997  8.996700e-07 -0.000496\n",
       "6249998  8.998300e-07 -0.000496\n",
       "6249999  8.999900e-07 -0.000495\n",
       "\n",
       "[6250000 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "681a897a-5337-4281-8b90-5c5783a84f55",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>C:\\Users\\MARTINA\\Desktop\\OOPROJECT\\pyproj\\bran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n events</th>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event length</th>\n",
       "      <td>6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time units</th>\n",
       "      <td>s\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ampl units</th>\n",
       "      <td>V\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              0\n",
       "path          C:\\Users\\MARTINA\\Desktop\\OOPROJECT\\pyproj\\bran...\n",
       "n events                                                   1000\n",
       "event length                                               6250\n",
       "time units                                                  s\\n\n",
       "ampl units                                                  V\\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "74dd8402-f961-4310-9717-6fc5a7b539c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.iloc[:,0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c690be96-6105-4b4a-847f-f5ad66c0230d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizzando l'evento numero 999\n",
      "Analysis completed.\n",
      "\n",
      "Process completed in 28.29 s.\n"
     ]
    }
   ],
   "source": [
    "single_wf = analysis(time_table, wf_table, N_of_events=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c1bad910-4754-409c-9846-ad6350fe4198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3504"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_wf.dropna().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9f1f6a7a-4b00-457f-a080-8559f94a72d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.962500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.930500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249995</th>\n",
       "      <td>1.861947e+03</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249996</th>\n",
       "      <td>1.861947e+03</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249997</th>\n",
       "      <td>1.861947e+03</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249998</th>\n",
       "      <td>1.861947e+03</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249999</th>\n",
       "      <td>1.861947e+03</td>\n",
       "      <td>-0.000495</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TIME       CH1  min\n",
       "0       -9.994500e-08 -0.000809  NaN\n",
       "1       -9.978500e-08 -0.000809  NaN\n",
       "2       -9.962500e-08 -0.000809  NaN\n",
       "3       -9.946500e-08 -0.000809  NaN\n",
       "4       -9.930500e-08 -0.000809  NaN\n",
       "...               ...       ...  ...\n",
       "6249995  1.861947e+03 -0.000496  NaN\n",
       "6249996  1.861947e+03 -0.000496  NaN\n",
       "6249997  1.861947e+03 -0.000496  NaN\n",
       "6249998  1.861947e+03 -0.000496  NaN\n",
       "6249999  1.861947e+03 -0.000495  NaN\n",
       "\n",
       "[6250000 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d3d51690-e9da-4b81-a272-6f680fdd81ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analysis(timestamp_table, wf_table, N_of_events=time_table.iloc[:,0].size,\n",
    "             threshold=0.006, distance=50,\n",
    "             inplace=True):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (V)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - RETURNS wf_table complete with all clean minima\n",
    "    - MUST HAVE inplace=True/False option: like this you're rewriting wf_table every time\n",
    "    - must decide if you want or not to be able to plot relative minima\n",
    "    \n",
    "    anyway, you can go on with the plot! Hurray!\n",
    "    #################################################################################\n",
    "    \n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    wf_datapoints = wf_table.iloc[:,0].size/1000 #N_of_events\n",
    "\n",
    "    general_clean_min = []\n",
    "    \n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        \n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "        \n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy() #(deep=False)\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = distance)[0]\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "        \n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        gap = threshold # default = 50\n",
    "        distance = distance # default = 50 \n",
    "        \n",
    "        clean_minimum_list = []\n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_clean_min.append(index + wf_index)\n",
    "    \n",
    "    wf_table.loc[:,'min'] = wf_table.loc[general_clean_min]['CH1']\n",
    "    \n",
    "    print('\\nAnalysis completed.')\n",
    "    print(\"\\nProcess completed in %s s.\" % (format(time.time()-start_time,\".2f\")))\n",
    "\n",
    "    return wf_table # general_clean_min"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d28bec3a-d269-4594-b041-494643aabbc7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "############################### COMMENTED VERSION ###################################\n",
    "\n",
    "def analysis(timestamp_table, wf_table, threshold=0.006, distance=50,\n",
    "            inplace=False):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (V)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    # Get number of events and number of points in each waveform\n",
    "    N_of_events = time_table.iloc[:,0].size\n",
    "    wf_datapoints = wf_table.iloc[:,0].size/N_of_events\n",
    "    \n",
    "    # There are 1000 events: each event is a single waveform, containing 6250 points.\n",
    "    # Pre-trigger signal is present: length of 250 data\n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "    # Conversion from relative times to absolute: timestamps of points of the waveform are summed to\n",
    "    # their relative trigger timestamp from timestamp_table\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "        \n",
    "    # Take a single waveform at a time\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        \n",
    "    # Make the list of the indexes of the relative minima in the waveform\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "    # Add list of minima to main dataframe\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "    # Compute baseline as average of first 250 wf datapoints, that constitute the pre-trigger region \n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        clean_minimum_list = []\n",
    "\n",
    "    # Define threshold for relative minimum to be considered good signal,\n",
    "    # and its minimum relative distance with respect to the prior minimum\n",
    "        gap = threshold # default = 50\n",
    "        distance = distance # default = 50 \n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        general_min_list = []\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "            \n",
    "    return single_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bf3047ae-a707-4815-9357-d754cc4fd475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6250000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table.iloc[:,0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3966d7ea-02a1-4a06-a9fe-b670db600e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## PLOTTING ##############################################\n",
    "def plot_wf(wf_table, N_of_events=1000, loop=False, show=True, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(V) vs timestamp(s) plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing, and shows the plot.\n",
    "\n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - see if this works :)\n",
    "    #################################################################################\n",
    "    \"\"\"\n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        wf_datapoints = wf_table.iloc[:,0].size/N_of_events\n",
    "        \n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        # plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        \n",
    "        if save==True:\n",
    "            figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "            plt.savefig(figure_path)\n",
    "\n",
    "        if show==True:\n",
    "            plt.show()\n",
    "            \n",
    "        plt.close()\n",
    "    \n",
    "        if loop!=True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84d2b92d-efef-4a6c-9c85-c0ffa26409ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop",
   "language": "python",
   "name": "oop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
