{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7d11171-dc97-4f4f-b0e7-d70389009d05",
   "metadata": {},
   "source": [
    "# DCR analysis\n",
    "\n",
    "## Processing of waveforms\n",
    "\n",
    "**GOAL**\n",
    "- count all events\n",
    "- make plot amplitude VS time to discriminate between 1 phe signals (\"real counts\" and afterpulses) and 2 phe signals (crosstalks)\n",
    "- evaluate % of afterpulses and crosstalks wrt total\n",
    "\n",
    "Notes: time axis has a physical minimum due to width of waveform\n",
    "\n",
    "**Procedure**\n",
    "- csv files of waveforms and timestamps combined\n",
    "- csv files, sliced into single waveforms\n",
    "- find minima (absolute and relative), plot them, count them (count single points of absolute minimum) and save their timestamps and amplitude\n",
    "- from amplitude value you understand if a peak is noise (crosstalk, afterpulse)\n",
    "- get amplitudes and timestamps of each minimum\n",
    "\n",
    "*Afterpulse*: happens tipically at 0.5 $\\mu$s after a real signal, and has an amplitude almost equal to 1 phe; threshold for considering an event an afterpulse of the event before is 6 $\\mu$s.  \n",
    "*Crosstalk*: single peak of amplitude 2 phe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ea419a-779a-433e-a335-d8c3d6a749ba",
   "metadata": {},
   "source": [
    "## Goals, tips and tricks\n",
    "\n",
    "You have to find an automated way to find the \"good\" absolute minimum.\n",
    "How?\n",
    "\n",
    "- [x] Extrapolate baseline: evaluate it by using only pre-trigger amplitudes.\n",
    "- [x] Discriminate if two peaks have a distance between each other that is too small (is less than the width of the window)\n",
    "- [x] **Raise an error or quarantine the snippet if you have a number of minima that is too big**\n",
    "    - implemented coding \"bad\" and \"good\" for clean_minima that are in wf with too many minima or with saturated, -inf data\n",
    "- [ ] **Evaluate the derivative of the ramp up of a peak**\n",
    "- [ ] Dark count rate is number of total events / total time --> **calculate total time**\n",
    "\n",
    "\n",
    "Options to follow to throw away noisy signals:\n",
    "\n",
    "1. Throw away all noise: if the waveform is not good (has more than one minimum that goes over the threshold) throw it away completely; have to count all the waveforms that are thrown and estimate fraction of total events\n",
    "2. Check on saturated events: must be true to have points over the threshold and also have some number of points (like, 10) in a very narrow range of values (all equal)\n",
    "\n",
    "Final goals:\n",
    "\n",
    "1. Create 2D plot with time deltas (x) and amplitude (y): time deltas are the differences between timestamps of any two successive \"good\" peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9520b95e-471f-4eb7-93fc-80b6b4612840",
   "metadata": {},
   "source": [
    "### Code from Guarise\n",
    "\n",
    "Already commented by Guarise, I already reviewed it."
   ]
  },
  {
   "cell_type": "raw",
   "id": "55e370e1-cdec-43a5-ac5f-6d971cc72343",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# timestamp_file_name è il path relativo del file di dati a partire dalla cwd\n",
    "timestamp_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\"             # nome del file con i timestamp del trigger\n",
    "\n",
    "# definisco l'indirizzo, os.path.join() unisce un indirizzo base al nome di un file specifico\n",
    "timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)                  # getcwd() restituisce l'indirizzo della cartella nella quale è contenuto questo programma\n",
    "\n",
    "timestamp_table = pd.read_csv(timestamp_path)                                   # leggo i dati relativi ai timestamp del trigger, disponendoli in un dataframe\n",
    "                                                                                # timestamp_table.head(10) per visualizzare i dati ottenuti\n",
    "\n",
    "\n",
    "# rinomino le colonne, Event è un indice che va da 1 a 1000 (numero di eventi), mentre Delta T è il tempo trascorso dal trigger precedente\n",
    "timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "N_of_events = len(timestamp_table)                                              # Numero di waveforms (o eventi), che corrisponde al numero di eventi di trigger\n",
    "# .diff effettua la somma cumulativa di ogni riga con quelle precedente\n",
    "timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)      # axis identifica l'asse, se lungo le righe (0) o lungo le colonne (1)\n",
    "wf_data_points = 0                                                              # inizializzo la variabile wf_data_point che corrisponde al numero di punti in ogni waveform (6250)\n",
    "\n",
    "# definisco il nome del file con i dati delle waveforms, questi dati sono posti in modo contiguo ovvero in un unico file csv\n",
    "# dividendo le righe in gruppi da 6250 elementi possiamo ottenere le singole waveforms\n",
    "wf_file_name = \".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\"                                    \n",
    "wf_path = os.path.join(os.getcwd(),wf_file_name)                                \n",
    "wf_table = pd.DataFrame()                                                       \n",
    "\n",
    "with open(wf_file_name, 'r') as file_wf:                                        # apro il file e inserisco le righe in una lista\n",
    "    lines = file_wf.readlines()\n",
    "    for line_counter, line in enumerate(lines):                                 # cerco la riga che inizia per TIME ma prima cerco Record Lenght per ottenere il valore di wf_data_point\n",
    "        if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # wf_data_poitns sono il numero di punti in ogni waveform\n",
    "        # un altro modo per ottenere N_of_events sarebbe cercare la riga che contiene il numero di frames (\"FastFrame Count,1000\") e dividere il numero totale di righe per il numero di frames\n",
    "        \n",
    "        if line.startswith(\"TIME\"):\n",
    "            wf_table = pd.read_csv(wf_path, header = line_counter-1)            # creo il dataframe dei dati delle wf considerando come header tutte le righe fino a TIME\n",
    "            break                                                               # esco dal ciclo"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58755126-54d9-4cdf-9e94-d3e2aa18ddeb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# metodo usato a lezione (meno elegante ma funziona comunque, riportato giusto per completezza)\n",
    "# line_counter = 0\n",
    "# n_line = -1\n",
    "# while n_line == -1:\n",
    "#     line = waveform_file.readline()\n",
    "#     line_counter += 1\n",
    "#     if line_counter == 100:\n",
    "#         print(\"ERROR\")\n",
    "# waveform_table = pd.read_csv(\"HPKR00030_2cicli_OV3_wf.csv\", header = n_line-1)\n",
    "\n",
    "# il metodo per il calcolo dei timestamp, allo stesso modo, è più elegante di quello trattato a lezione, che riporto qui sotto per completezza\n",
    "# timestamp_table.at[0,'Timestamp'] = timestamp_table.iloc[0]['Delta T']\n",
    "# for i in timestamp_table.index[1:]:\n",
    "#     timestamp_table.at[i,\"Timestamp\"] = timestamp_table.at[i-1,\"Timestamp\"] + timestamp_table.at[i,\"Delta T\"]\n",
    "\n",
    "# funzione di analisi per la ricerca dei minimi\n",
    "def analysis(timestamp_table, wf_table,wf_datapoints):\n",
    "# inizializzo un dataframe generale\n",
    "    general_min_list = []\n",
    "\n",
    "# cicla con un contatore che scorre su tutto il range lungo come il numero di eventi di trigger\n",
    "    for n in range(N_of_events):\n",
    "# end = '\\r' inserisce \\r alla fine della stringa, quindi riporta il puntatore all'inizio della riga in modo da sovrascrivere l'output precedente\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r')\n",
    "# nome del singolo evento analizzato in questa iterazione del ciclo\n",
    "# preparo già il nome con l'estensione giusta per quando stamperò l'immagine della waveform\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "\n",
    "# prima di estrarre i punti relativi alla singola waveform, convertiamo i tempi relativi in tempi assoluti\n",
    "# la colonna \"TIME\" contiene, per ogni waveform, i tempi relativi all'evento di trigger che ha avviato l'acquisizione della waveform\n",
    "# per convertire questi tempi relativi in tempi assoluti (o meglio relativi all'inizio della misura) dobbiamo aggiungere ai tempi di ogni waveform il corrispondente timestamp del trigger\n",
    "        wf_table[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]\n",
    "\n",
    "# estraggo una singola waveform, ovvero 6250 punti, dalla tabella principale\n",
    "# single_wf è un DataFrame\n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "\n",
    "# la funzione argrelextrema restituisce gli estremi relativi, calcolati in base all'operatore np.less_equal\n",
    "# aumentando l'ordine diminuiamo il numero di minimi trovati\n",
    "# Il range totale di punti viene suddiviso in intervalli di lunghezza proporzionale a \"order\", successivamente viene \n",
    "# estratto il minimo assoluto di ogni intervallo:\n",
    "# i minimi così trovati sono i minimi relativi restituiti dalla funzione argrelextrema\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = 50)[0]\n",
    "\n",
    "# la riga seguente serve per identificare i minimi ed inserirli nella singola waveform, in modo da vederli nei plot\n",
    "        single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "\n",
    "# eseguo un fit di ordine 0 (quindi una media aritmetica) sui primi 250 punti, che rientrano nella zona di pre-trigger\n",
    "# (ovvero i punti precedenti all'evento di trigger), per determinare la baseline del segnale\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "# definisco una lista di minimi \"buoni\" da riempire in seguito\n",
    "        clean_minimum_list = []\n",
    "\n",
    "############################# Soglia scelta per bontà minimo ##################################\n",
    "# i minimi saranno considerati buoni se hanno ampiezza superiore a 0.006, rispetto alla baseline\n",
    "# e se hanno una distanza dall'indice precedente di almeno 50 dati\n",
    "        gap = 0.006 # mV\n",
    "        distance = 50\n",
    "###############################################################################################\n",
    "        \n",
    "        previous_index = minimum_list[0]\n",
    "        for index in minimum_list:\n",
    "# un controllo sugli indici previene massimi vicini \n",
    "# (provate a togliere and (index > previous_index + 50) e vedete cosa succede)\n",
    "# se l'indice del minimo attuale dista dal suo precedente di almeno distance, allora appendo\n",
    "# l'indice del dato individuato come minimo \"buono\" alla lista clean_minimum_list\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                previous_index = index\n",
    "                \n",
    "# aggiungo la colonna di minimi \"buoni\" alla tabella\n",
    "        single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "\n",
    "# l'indice corrispettivo sulla tabella principale è sfasato di un valore n*6250\n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_min_list.append(index + wf_index)\n",
    "\n",
    "# le seguenti linee di comando servono per graficare le singole waveforms\n",
    "# !!!!!!!!! attenzione al numero di cicli nel for, altrimenti aprite 6250 grafici !!!!!!!!!\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "        plt.savefig(figure_path)\n",
    "        plt.close()\n",
    "        \n",
    "        ####################### Evitiamo disastri ##################################\n",
    "        break\n",
    "        ############################################################################\n",
    "        \n",
    "    print('Analisi completata!!                       ')\n",
    "    return general_min_list\n",
    "\n",
    "# ora abbiamo una lista di minimi considerati validi, con rispettivi tempi e ampiezze (e altre colonne ridondanti che servivano per i plot)\n",
    "min_list = analysis(timestamp_table, wf_table,wf_data_points)\n",
    "\n",
    "# seleziono solo le righe corrispondenti ai minimi validi, utilizzando la lista di indici definita prima\n",
    "minimum_table = wf_table.loc[min_list].copy()\n",
    "\n",
    "# infine calcolo le differenze dei tempi relativi ai minimi delle waveforms\n",
    "# diff calcola, per ogni riga, la differenza con la riga precedente\n",
    "# (o due righe indietro se periods =2, o tre se periods=3, ecc)\n",
    "minimum_table['TIME'] = minimum_table['TIME'].diff(periods=1)\n",
    "minimum_table = minimum_table.iloc[1:,:]\n",
    "\n",
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "minimum_table.rename(columns={'TIME':'Delta T (s)','CH1':'Amplitude (V)'}, inplace = True)\n",
    "plt.scatter(minimum_table['Delta T (s)'],minimum_table['Amplitude (V)'])\n",
    "plt.xscale(\"log\")\n",
    "plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e. (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765ac2ff-870f-4cf7-a433-22a2038ab205",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### My code structure\n",
    "\n",
    "Starting from code from Guarise, polishing and dividing in different functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6289bb-5c4d-4abc-b912-7a316d36e7b8",
   "metadata": {},
   "source": [
    "**Header**\n",
    "```python\n",
    "\n",
    "def read_wf(file_name):\n",
    "    \"\"\"\n",
    "    Basic read function with automatic timestamp or wf detection from file_name;\n",
    "    also constructs both dataframes\n",
    "    \"\"\"\n",
    "    if file name contains 'time.csv' then do...\n",
    "    if else file_name contains wf.csv then do...\n",
    "    else NameError\n",
    "        raise\n",
    "\n",
    "def analysis_wf(timestamp_table, wf_table, wf_datapoints, threshold, distance, inplace=True):\n",
    "    \"\"\"\n",
    "    This function finds all the minima in the waveforms and selects the \"good ones\" based on\n",
    "    - minim amplitude = threshold (mV)\n",
    "    - number of data in between two consecutive absolute minima = distance (adim, integer)\n",
    "    Option inplace tells if the function modifies the original wf dataframe by adding a column with good minima.\n",
    "    if inplace == True: return nothing\n",
    "    if inplace == False: return copy of original dataframe with new column of good minima\n",
    "    \"\"\"\n",
    "    \n",
    "def plot_wf(timestamp_table, wf_table, wf_datapoints, loop=True, show=False, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(mV) vs timestamp plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True loops on all the wf,\n",
    "    otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing.\n",
    "    \"\"\"\n",
    "\n",
    "def plot_dcr(minimum_table, hist=True):\n",
    "    \"\"\"\n",
    "    Only needs a dataframe minimum_table with the list of the minima and the related timestamps.\n",
    "    Plots an amplitude (mV) vs delta_t (ns) graph, useful to detect noise source.\n",
    "    Option hist=True plots an histogram subplot under the 2D plot, representing the integral in the vertical\n",
    "    direction of the ampli vs dt plot.\n",
    "    \"\"\"\n",
    "```\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "256b9cf8-9082-41d9-a612-147baed5fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6d5fc-d1c0-4d41-ab4c-5cd834611641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dcr_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2e72f-8d6c-4892-8d01-578f6862d437",
   "metadata": {},
   "source": [
    "## Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "752c597c-4983-4c03-bcd9-eabf23c1b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wf(fname):\n",
    "    \"\"\"Basic read function with automatic timestamp or wf file type detection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    - fname: relative path of the file with respect to the current working directory\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas' dataframe of the data provided.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # If the file provided is a timestamp file, follow this routine:\n",
    "    # - open the file\n",
    "    # - make a dataframe with the timestamps; the header is as default in line 0\n",
    "    # - timestamps are relative and provide the time interval with respect to the previous trigger:\n",
    "    #    make them absolute by computing the cumulative of each timestamp with cumsum method of pd\n",
    "    if re.search(\"time.csv\", fname): \n",
    "        timestamp_file_name = fname\n",
    "        timestamp_path = os.path.join(os.getcwd(),timestamp_file_name)\n",
    "        timestamp_table = pd.read_csv(timestamp_path) \n",
    "            # if file is not found, FileNotFoundError is raised automatically\n",
    "        timestamp_table.rename(columns = {'X: (s)': 'Event', 'Y: (Hits)':'Timestamp'}, inplace = True)\n",
    "        N_of_events = len(timestamp_table) # = 1000\n",
    "        timestamp_table[\"Timestamp\"] = timestamp_table[\"Timestamp\"].cumsum(axis=0)\n",
    "        \n",
    "        return timestamp_table\n",
    "        \n",
    "    # If the file provided is a waveform file, follow this routine:\n",
    "    # - open the file\n",
    "    # - detect the number of datapoints in each waveform, wf_datapoints = 6250\n",
    "    # - detect end of header (\"TIME\") and make a dataframe with the wf data\n",
    "    elif re.search(\"wf.csv\", fname):\n",
    "        wf_file_name = fname\n",
    "        wf_path = os.path.join(os.getcwd(),wf_file_name)\n",
    "        wf_table = pd.DataFrame()\n",
    "        \n",
    "        with open(wf_file_name, 'r') as file_wf:\n",
    "                # if file is not found, FileNotFoundError is raised automatically\n",
    "            lines = file_wf.readlines()\n",
    "            for line_counter, line in enumerate(lines):\n",
    "                if line.startswith(\"Record Length\"): wf_datapoints = int(line.split(',')[-1]) # = 6250\n",
    "                if line.startswith(\"Horizontal\"): time_unit = str(line.split(',')[-1]).rstrip(\"\\n\") # = s\\n\n",
    "                if line.startswith(\"Vertical\"): ampl_unit = str(line.split(',')[-1]).rstrip(\"\\n\") # = V\\n\n",
    "                if line.startswith(\"FastFrame\"): wf_events = int(line.split(',')[-1]) # = 1000\n",
    "                    # To implement when both files are required by the function\n",
    "                    # if wf_events != N_of_events: break\n",
    "                if line.startswith(\"TIME\"):\n",
    "                    wf_table = pd.read_csv(wf_path, header = line_counter-1)\n",
    "                    break\n",
    "        \n",
    "        meta = {\n",
    "            'path' : wf_path,\n",
    "            'n events' : wf_events,\n",
    "            'data points' : wf_datapoints,\n",
    "            'time units' : time_unit,\n",
    "            'ampl units' : ampl_unit,}\n",
    "                    \n",
    "        return wf_table, meta\n",
    "    \n",
    "    else:\n",
    "        raise NameError(\"Please provide the path to a waveform or timestamp comma-separated file (.csv).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d170e5c-8250-41a1-b229-60734dea95e7",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "da1c76fd-5755-4b66-9356-4767313f154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# VERSION WITHOUT INPLACE #############################################\n",
    "############################# VERSION WITH COPY OF WF_TABLE #############################################\n",
    "\n",
    "\n",
    "def analysis(timestamp_table, wf_table, meta, custom_n_events=1000, time_adjust=True,\n",
    "             threshold=0.006, distance=50, many_minima=6250,\n",
    "             plot=False, save_plot=False):\n",
    "    \"\"\"Function to analyze waveform data and locate clean signal peaks.\n",
    "    \n",
    "    This function finds all the minima in each waveform (wf) and selects the \"good ones\" (clean_min) based on\n",
    "    threshold (V) and distance (#). The resulting dataframe has a column \"code\" that indicates if\n",
    "    a clean_min belongs to a good or bad wf: bad wfs are the ones containing a number of relative minima\n",
    "    bigger than many_minima or that contain -inf saturated data. Notice that the \"good\" or \"bad\" coding\n",
    "    makes sense for discriminating between equally clean_min only: discrimination is not provided for\n",
    "    minima that are not considered to be \"good\" signal.\n",
    "   \n",
    "   ------\n",
    "   Input:\n",
    "   - timestamp_table: pandas.DataFrame\n",
    "       Dataframe with timestamps\n",
    "   - wf_table: pandas.DataFrame\n",
    "       Dataframe with waveforms in list mode\n",
    "   - meta: dict\n",
    "       Dictionary with metadata of wf_table\n",
    "   - custom_n_events: int, default 1000\n",
    "       Number of events to analyze (starts from the first waveform in any case)\n",
    "   - time_adjust: bool, default True\n",
    "       If True, adds timestamps from timestamp_table to wf_table. May be kept\n",
    "       True for the first time the analysis is run on the dataset, switch\n",
    "       to False afterwards.\n",
    "   - threshold: float, default 0.006 [V]\n",
    "       Minimum value of signal to discriminate it from noise, in units of V\n",
    "   - distance: int, default 50\n",
    "       Number of data in between two consecutive absolute minima\n",
    "   - many_minima: int, default 6250 (# data in single waveform)\n",
    "       Provide a number of minimum minima to be found to turn on or off a warning \n",
    "       that is raised if in the waveform there are more than that number of minima.\n",
    "       Also provides additional column in dataframe with code \"bad_wf\" for\n",
    "       waveforms that satisfy the above condition.\n",
    "   - plot: bool, default False\n",
    "       If True, plot the scatterplot of the waveforms with the relative minima in a\n",
    "       recursive way\n",
    "   \n",
    "   --------\n",
    "   Returns:\n",
    "   - copy of original dataframe with added columns of minima (total) and clean minima (based\n",
    "       on threshold and distance)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    ############################# UPDATES TO MAKE ####################################\n",
    "    # - [x] RETURNS wf_table complete with all clean minima\n",
    "    # - [x] MUST HAVE inplace=True/False option: like this you're rewriting wf_table every time\n",
    "    # - [x] must decide if you want or not to be able to plot relative minima\n",
    "    # - [x] discard saturated waveforms: must have a lot of almost-same-amplitude points\n",
    "    #     this is already done since dense minima would be discarded from clean by default \n",
    "    # - [x] set as bad wf containing -inf data\n",
    "    # - [x] identify waveforms with too many minima\n",
    "    #     - [x] count # of discarded waveforms and get fraction wrt total \n",
    "    # - [x] Add tag \"bad\" along with minimum list, to be added as column in final, total df\n",
    "    # - [x] clean_min must contain effective signal amplitude (difference wrt baseline), not absolute\n",
    "    # - [x] metadata update with number of analysis already performed\n",
    "    ##################################################################################\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    N_of_events = custom_n_events        \n",
    "    wf_datapoints = len(wf_table)/1000\n",
    "    \n",
    "    copy = wf_table.copy()\n",
    "    general_clean_ampl = []\n",
    "    general_clean_min = []\n",
    "    general_bad = []\n",
    "    time_list = []\n",
    "    N_bad_wf = 0\n",
    "        \n",
    "    for n in range(N_of_events):\n",
    "        print(\"Analysis of event number \" + str(n+1), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        \n",
    "        if time_adjust == True:\n",
    "            copy[\"TIME\"].loc[wf_datapoints*n: (wf_datapoints*(n+1))-1] += timestamp_table.at[n,\"Timestamp\"]            \n",
    "        \n",
    "        single_wf = copy.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        minimum_list = argrelextrema(single_wf.CH1.values, np.less_equal, order = distance)[0]\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "        time_list.append(single_wf.TIME.max()-single_wf.TIME.min())\n",
    "\n",
    "        gap = threshold\n",
    "        clean_minimum_list = []\n",
    "        previous_index     = minimum_list[0]\n",
    "        \n",
    "        for index in minimum_list:\n",
    "            if (baseline - single_wf[\"CH1\"].iat[index] > gap) and (index > previous_index + distance):\n",
    "                clean_minimum_list.append(index)\n",
    "                general_clean_ampl.append(baseline - single_wf[\"CH1\"].iat[index])\n",
    "                previous_index = index\n",
    "                        \n",
    "        inf_counts = 0\n",
    "        inf_counts = len(single_wf[single_wf.CH1==-np.inf])\n",
    "        if inf_counts > 0:\n",
    "            N_bad_wf += 1\n",
    "        \n",
    "        wf_index = (n*wf_datapoints)\n",
    "        for index in clean_minimum_list:\n",
    "            general_clean_min.append(index + wf_index)\n",
    "            \n",
    "            if len(minimum_list) > many_minima or inf_counts > 0: # implement or for wf containing -inf data \n",
    "                general_bad.append(index + wf_index)\n",
    "        \n",
    "        # Plotting control (inside loop)\n",
    "        if plot==True:\n",
    "            single_wf.loc[:,'min'] = single_wf.iloc[minimum_list]['CH1']\n",
    "            single_wf.loc[:,'clean_min'] = single_wf.iloc[clean_minimum_list]['CH1']\n",
    "            plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "            plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "            plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "            plt.axhline(baseline, c='b')\n",
    "            plt.show()\n",
    "            \n",
    "        if save_plot==True:\n",
    "            figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "            plt.savefig(figure_path)\n",
    "            plt.close()\n",
    "    \n",
    "    # Metadata update\n",
    "    total_time = sum(time_list)\n",
    "    meta['total acquis time'] = total_time\n",
    "    meta['n clean minima'] = len(general_clean_min)-len(general_bad)\n",
    "    meta['n bad minima'] = len(general_bad)\n",
    "    meta['DCR'] = meta[\"n clean minima\"]/total_time\n",
    "    \n",
    "    # Printed output\n",
    "    print('\\nAnalysis completed.')\n",
    "    print('Number of clean minima found: ', len(general_clean_min)-len(general_bad))\n",
    "    print('Fraction of waveforms with too many minima or -inf data (\"bad_wf\") on total: %s%%' % format(N_bad_wf/custom_n_events*100,\".2f\"))\n",
    "    print('Total acquisition time: {0:0.3e} s'.format(total_time))\n",
    "    print('Estimated DCR: {0:0.3e} Hz'.format(meta[\"n clean minima\"]/total_time))\n",
    "        \n",
    "    # Return control\n",
    "    clean_ampl = pd.DataFrame(general_clean_ampl, index=general_clean_min, columns=['ampl_min'])\n",
    "    if many_minima < 6250 or len(general_bad) > 0:\n",
    "        bad_list = ['bad_wf' for item in general_bad]\n",
    "        bad = pd.DataFrame(bad_list, index=general_bad, columns=['code'])\n",
    "        \n",
    "    copy.loc[:,'clean_min'] = copy.iloc[general_clean_min]['CH1']\n",
    "    copy = copy.join(clean_ampl)\n",
    "    copy = copy.join(bad)\n",
    "    copy.code.fillna(value='good', inplace=True)\n",
    "    copy['wfID'] = np.array(range(len(copy))) // 6250\n",
    "    copy.set_index('wfID', append=True, inplace=True)\n",
    "    print(\"Process completed in %s s.\" % (format(time.time()-start_time,\".2f\")))\n",
    "    return copy, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "476a4d97-7fe2-45bf-bc24-0544ed306762",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def analysis_delta_t(analyzed_wf, meta,\n",
    "                    noise_list=['primary dark counts', 'delayed crosstalk', 'crosstalk', 'afterpulses'],\n",
    "                    crosstalk_thr=10e-3, delayed_cross_thr=6e-6,\n",
    "                    ):\n",
    "    \"\"\"Function to polish the dataframe returned from the analysis function and discriminate between noise.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    mins = analyzed_wf.dropna() # drops all rows with NaNs, that are found in clean_min only\n",
    "    mins = mins.loc[mins.code=='good']\n",
    "    mins['TIME'] = mins['TIME'].diff(periods=1)\n",
    "    mins = mins.iloc[1:,[0,-2]]\n",
    "    mins.rename(columns={'TIME':'Delta T (s)','ampl_min':'Amplitude (V)'}, inplace = True)\n",
    "    \n",
    "    def noise_discrimination(df, crosstalk_thr=10e-3, delayed_cross_thr=6e-6):\n",
    "            primary_mean = df.groupby(by=[df['Amplitude (V)'] < crosstalk_thr]).get_group(True)['Amplitude (V)'].mean()\n",
    "            primary_std = df.groupby(by=[df['Amplitude (V)'] < crosstalk_thr]).get_group(True)['Amplitude (V)'].std()\n",
    "            df['Noise'] = (\n",
    "                np.where(\n",
    "                    df['Amplitude (V)'] > crosstalk_thr , 'crosstalk',\n",
    "                    np.where(df['Delta T (s)'] < delayed_cross_thr, 'delayed crosstalk', 'primary dark counts')))\n",
    "            df.loc[df['Amplitude (V)'] < (primary_mean-3*primary_std)]['Noise'].apply(lambda x : 'afterpulses')\n",
    "            return df\n",
    "    \n",
    "    mins = noise_discrimination(mins)\n",
    "    \n",
    "    return mins, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3331e8-c698-4834-8b6b-9993e855dd0e",
   "metadata": {},
   "source": [
    "## Plot scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966d7ea-02a1-4a06-a9fe-b670db600e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## PLOTTING ##############################################\n",
    "def plot_wf(wf_table, N_of_events=1000, loop=False, show=True, save=False,): #wf_table must contain the \"good minima\" column\n",
    "    \"\"\"\n",
    "    This function plots the waveform by its data, in a amplitude(V) vs timestamp(s) plot.\n",
    "    Automatically detects if the dataframe contains one or more waveforms and if loop==True\n",
    "    loops on all the wf, otherwise only plots the first one (good for debuggind/building phases)\n",
    "    Options:\n",
    "    - show scatter only (wf) [doesn't require \"good minima\" column]\n",
    "    - show minima\n",
    "    This function returns nothing, and shows the plot.\n",
    "\n",
    "    ############################ UPDATES TO MAKE ####################################\n",
    "    - see if this works :)\n",
    "    #################################################################################\n",
    "    \"\"\"\n",
    "    for n in range(N_of_events): # N_of_events = 1000\n",
    "        print(\"Analizzando l'evento numero \" + str(n), end='\\r') #'\\r' overwrites output\n",
    "        event_name = 'Event_' + str(n) + '.png'\n",
    "        wf_datapoints = wf_table.iloc[:,0].size/N_of_events\n",
    "        \n",
    "        single_wf = wf_table.loc[wf_datapoints*n: (wf_datapoints*(n+1))-1].copy()\n",
    "        baseline = np.polyfit(single_wf[\"TIME\"].iloc[0:250], single_wf[\"CH1\"].iloc[0:250],0)[0]\n",
    "\n",
    "        plt.plot(single_wf[\"TIME\"], single_wf['CH1'], linestyle=\"-\", linewidth=1)\n",
    "        # plt.scatter(single_wf[\"TIME\"], single_wf['min'], color=\"darkred\")\n",
    "        plt.scatter(single_wf[\"TIME\"], single_wf['clean_min'], color=\"green\")\n",
    "        plt.axhline(baseline, c='b')\n",
    "        \n",
    "        if save==True:\n",
    "            figure_path = os.path.join(os.path.join(os.getcwd(),'grafici'), event_name)\n",
    "            plt.savefig(figure_path)\n",
    "\n",
    "        if show==True:\n",
    "            plt.show()\n",
    "            \n",
    "        plt.close()\n",
    "    \n",
    "        if loop!=True:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e6bb2-739e-4ad5-bbba-6ffbedce6267",
   "metadata": {},
   "source": [
    "## Plot 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eaf6e2f3-fa02-4c99-a2d3-b02fa9e71bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(data, sns_palette='deep', title='2D plot',\n",
    "            show=True, save=False, save_path='./Amplitude_vs_dt.', save_extension='pdf',\n",
    "            **kwargs,):\n",
    "    \"\"\"2D plot with amplitude (V) vs time delta (s) scatterplot and kernel density estimation.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    from matplotlib.patches import Patch\n",
    "    from matplotlib.lines import Line2D\n",
    "            \n",
    "    f, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True, sharey=False)\n",
    "    ax1 = axs[0]\n",
    "    ax2 = axs[1]\n",
    "    \n",
    "    mins = data\n",
    "    sns.scatterplot(data=mins, x=\"Delta T (s)\", y=\"Amplitude (V)\", hue=\"Noise\", ax=ax1,\n",
    "                    alpha=0.7, legend=False, palette=sns_palette)\n",
    "    sns.kdeplot(data=mins, x=\"Delta T (s)\", hue=\"Noise\", ax=ax2,\n",
    "                 multiple=\"stack\", fill=True, log_scale=True, common_norm=True,\n",
    "                 edgecolor='white', alpha=0.7, palette=sns_palette,\n",
    "                 legend=False)\n",
    "    \n",
    "    ax1.set_title(title, fontsize=14)\n",
    "    ax1.set_xscale('log')\n",
    "    ax2.set_xscale('log')\n",
    "    ax2.set_ylabel('Density (%)')\n",
    "    \n",
    "    n_mins = len(mins)\n",
    "    noise_list_red = mins.groupby('Noise').count().index.values\n",
    "    noise_list_red = sorted(noise_list_red, reverse=True)\n",
    "    \n",
    "    noise_mean_t = [mins.groupby('Noise').mean().loc[i]['Delta T (s)'] for i in noise_list_red]\n",
    "    noise_percent = [mins.groupby('Noise').count().loc[i].values[0]/n_mins*100 for i in noise_list_red]\n",
    "    \n",
    "    deep_cmap = sns.color_palette(sns_palette, 10)\n",
    "    palette = sns.color_palette([deep_cmap[i] for i in range(len(noise_list_red))])\n",
    "    \n",
    "    legend_scatter = [Line2D([0], [0], marker='o', color='w', label=f'{noise_list_red[i]}',\n",
    "                              markerfacecolor=palette[i], markersize=8) for i in range(len(noise_list_red))]\n",
    "    \n",
    "    legend_kde = [Line2D([0], [0], marker='o', color='w', label=f'{noise_list_red[i]} '+'({0:0.1f}%)'.format(noise_percent[i]),\n",
    "                              markerfacecolor=palette[i], markersize=8) for i in range(len(noise_list_red))]\n",
    "    \n",
    "    ax1.legend(handles=legend_scatter, loc='upper left')\n",
    "    ax2.legend(handles=legend_kde, loc='upper left') #bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    \n",
    "    if show==True:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    \n",
    "    if save==True:\n",
    "        f.savefig(save_path+save_extension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b0743b-9256-405e-895d-114a1e6b17bb",
   "metadata": {},
   "source": [
    "# Blocks for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a30ae291-8c98-4b4b-a7a1-94fdbacb45c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_table, meta = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "e5f90ef4-d097-4860-8cd9-209a39513321",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'C:\\\\Users\\\\MARTINA\\\\Desktop\\\\OOPROJECT\\\\pyproj\\\\branch_dcr\\\\.\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_wf.csv',\n",
       " 'n events': 1000,\n",
       " 'data points': 6250,\n",
       " 'time units': 's',\n",
       " 'ampl units': 'V'}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bc91e6e-ecfa-46a8-8184-23f0dc106e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_table = read_wf(\".\\\\Data\\\\DCR\\\\HPKR00030_2cicli_OV3_time.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f5f12f0-e5f6-4026-96a6-cb0080bee5ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6250000 entries, 0 to 6249999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   TIME    float64\n",
      " 1   CH1     float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 95.4 MB\n"
     ]
    }
   ],
   "source": [
    "wf_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9002beab-6f7c-4528-a4d8-ea4b4ff521f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIME</th>\n",
       "      <th>CH1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.994500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.978500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.962500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.946500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.930500e-08</td>\n",
       "      <td>-0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249995</th>\n",
       "      <td>8.993500e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249996</th>\n",
       "      <td>8.995100e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249997</th>\n",
       "      <td>8.996700e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249998</th>\n",
       "      <td>8.998300e-07</td>\n",
       "      <td>-0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249999</th>\n",
       "      <td>8.999900e-07</td>\n",
       "      <td>-0.000495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TIME       CH1\n",
       "0       -9.994500e-08 -0.000809\n",
       "1       -9.978500e-08 -0.000809\n",
       "2       -9.962500e-08 -0.000809\n",
       "3       -9.946500e-08 -0.000809\n",
       "4       -9.930500e-08 -0.000809\n",
       "...               ...       ...\n",
       "6249995  8.993500e-07 -0.000496\n",
       "6249996  8.995100e-07 -0.000496\n",
       "6249997  8.996700e-07 -0.000496\n",
       "6249998  8.998300e-07 -0.000496\n",
       "6249999  8.999900e-07 -0.000495\n",
       "\n",
       "[6250000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wf_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e57ff7-3228-4ae2-9ec1-7971e9c0c85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.015771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.020706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.030981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event  Timestamp\n",
       "0      0   0.000000\n",
       "1      1   0.015416\n",
       "2      2   0.015771\n",
       "3      3   0.020706\n",
       "4      4   0.030981"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "96df91c0-5869-4c4a-8e5d-bdbcc27b7fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis of event number 1000\n",
      "Analysis completed.\n",
      "Number of clean minima found:  1073\n",
      "Fraction of waveforms with too many minima or -inf data (\"bad_wf\") on total: 1.10%\n",
      "Total acquisition time: 9.998e-04 s\n",
      "Estimated DCR: 1.073e+06 Hz\n",
      "Process completed in 31.92 s.\n"
     ]
    }
   ],
   "source": [
    "wf, meta = analysis(time_table, wf_table, meta, plot=False, many_minima=500, time_adjust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ce6ce3a7-7e8a-4ce9-aacd-81f0421b8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mins, meta = analysis_delta_t(wf, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f189d879-c552-47ea-865a-f566089aac52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Delta T (s)</th>\n",
       "      <th>Amplitude (V)</th>\n",
       "      <th>Noise</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>wfID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <th>1</th>\n",
       "      <td>0.015416</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13221</th>\n",
       "      <th>2</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19473</th>\n",
       "      <th>3</th>\n",
       "      <td>0.004935</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25721</th>\n",
       "      <th>4</th>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31971</th>\n",
       "      <th>5</th>\n",
       "      <td>0.004953</td>\n",
       "      <td>0.006906</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219475</th>\n",
       "      <th>995</th>\n",
       "      <td>0.017280</td>\n",
       "      <td>0.007405</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225725</th>\n",
       "      <th>996</th>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231979</th>\n",
       "      <th>997</th>\n",
       "      <td>0.017403</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238221</th>\n",
       "      <th>998</th>\n",
       "      <td>1.396270</td>\n",
       "      <td>0.007116</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244475</th>\n",
       "      <th>999</th>\n",
       "      <td>1.322320</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>primary dark counts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1072 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Delta T (s)  Amplitude (V)                Noise\n",
       "        wfID                                                 \n",
       "6974    1        0.015416       0.007200  primary dark counts\n",
       "13221   2        0.000355       0.007230  primary dark counts\n",
       "19473   3        0.004935       0.007261  primary dark counts\n",
       "25721   4        0.010274       0.007147  primary dark counts\n",
       "31971   5        0.004953       0.006906  primary dark counts\n",
       "...                   ...            ...                  ...\n",
       "6219475 995      0.017280       0.007405  primary dark counts\n",
       "6225725 996      0.017200       0.007479  primary dark counts\n",
       "6231979 997      0.017403       0.007661  primary dark counts\n",
       "6238221 998      1.396270       0.007116  primary dark counts\n",
       "6244475 999      1.322320       0.007450  primary dark counts\n",
       "\n",
       "[1072 rows x 3 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "27a81c80-b741-4a7b-ba1a-e8f44357edd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# una volta trovati tutti picchi possiamo costruire il grafico ed estrarre i valori di DCR, AP e CT\n",
    "\n",
    "fig, axs = plt.subplots(2,1,figsize=(10,5), sharex=True, squeeze=True,)\n",
    "\n",
    "# axs[0].scatter(mins['Delta T (s)'],mins['Amplitude (V)'])\n",
    "# axs[0].set_xscale('log')\n",
    "\n",
    "# hist, bins, _ = plt.hist(mins['Delta T (s)'], bins=100,)\n",
    "axs[1].hist(mins['Delta T (s)'], bins=logbins)\n",
    "axs[1].set_xscale('log')\n",
    "\n",
    "# plt.savefig('Amplitude_vs_dt.pdf')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# La Dark Count Rate è semplicemente il numero di eventi considerati validi, diviso per il tempo \n",
    "# totale di misura\n",
    "# la probabilità di After Pulse è la precentuale di eventi con delta t inferiore a 6 microsecondi\n",
    "# la probabilità di Cross Talk è la percentuale di eventi con ampiezza superiore a 1 p.e.\n",
    "# (p.e. = fotoelettrone, nel nostro caso pari a 8 mV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "62078a39-d2e9-4f33-88be-abf285e3afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(mins, show=False, save=True, save_extension='pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "895daa2e-d1c0-4193-ae88-d24b3a3611e8",
   "metadata": {},
   "source": [
    "    ############################# UPDATES TO MAKE ####################################\n",
    "    # - [x] discard -inf values\n",
    "    # - [x] establish log binning on x axis\n",
    "    # - [x] calculate total time\n",
    "    #     - [x] COMPUTE DCR\n",
    "    #     - [ ] annotate all of this on the plot\n",
    "    # - [x] compute afterpulses %, compute cross talk %\n",
    "    # - [x] different colors for different kinds of noise\n",
    "    # - [ ] make everything a function\n",
    "    ##################################################################################\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "        \n",
    "f, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True, sharey=False)\n",
    "ax1 = axs[0]\n",
    "ax2 = axs[1]\n",
    "\n",
    "scatter = sns.scatterplot(data=mins, x=\"Delta T (s)\", y=\"Amplitude (V)\", hue=\"Noise\", ax=ax1,\n",
    "                alpha=0.7, legend=False, palette='deep')\n",
    "kde = sns.kdeplot(data=mins, x=\"Delta T (s)\", hue=\"Noise\", ax=ax2,\n",
    "             multiple=\"stack\", fill=True, log_scale=True, common_norm=True,\n",
    "             edgecolor='white', alpha=0.7, palette='deep',\n",
    "             legend=False)\n",
    "\n",
    "title = \"DCR - 2D plot\"\n",
    "ax1.set_title(title, fontsize=14)\n",
    "ax1.set_xscale('log')\n",
    "# ax1.axes.xaxis.set_visible(False)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_xlim()\n",
    "ax2.set_ylabel('Density (%)')\n",
    "\n",
    "# t = scatter.text(\n",
    "#     0, 0, \"Direction\", ha=\"center\", va=\"center\", rotation=45, size=15,\n",
    "#     bbox=dict(boxstyle=\"rarrow,pad=0.3\", fc=\"cyan\", ec=\"b\", lw=2))\n",
    "\n",
    "\n",
    "\n",
    "# text = (f\"{title}\"\n",
    "#         \"\\nAnd so on\")\n",
    "# text_kwargs = dict(ha='left', va='center', fontsize=12, color='black')\n",
    "# scatter.annotate(text, xy=(0,0.9),  xycoords='axes fraction',\n",
    "#                  xytext=(0.01, 0.9), textcoords='axes fraction',\n",
    "#                  horizontalalignment='right', verticalalignment='top',\n",
    "#                  bbox=dict(facecolor='white', alpha=0.5),\n",
    "#                  **text_kwargs,\n",
    "#              )\n",
    "\n",
    "n_mins = len(mins)\n",
    "noise_list_red = mins.groupby('Noise').count().index.values\n",
    "noise_list_red = sorted(noise_list_red, reverse=True)\n",
    "\n",
    "noise_mean_t = [mins.groupby('Noise').mean().loc[i]['Delta T (s)'] for i in noise_list_red]\n",
    "noise_percent = [mins.groupby('Noise').count().loc[i].values[0]/n_mins*100 for i in noise_list_red]\n",
    "\n",
    "deep_cmap = sns.color_palette(\"deep\", 10)\n",
    "palette = sns.color_palette([deep_cmap[i] for i in range(len(noise_list_red))])\n",
    "\n",
    "legend_scatter = [Line2D([0], [0], marker='o', color='w', label=f'{noise_list_red[i]}',\n",
    "                          markerfacecolor=palette[i], markersize=8) for i in range(len(noise_list_red))]\n",
    "\n",
    "legend_kde = [Line2D([0], [0], marker='o', color='w', label=f'{noise_list_red[i]} '+'({0:0.1f}%)'.format(noise_percent[i]),\n",
    "                          markerfacecolor=palette[i], markersize=8) for i in range(len(noise_list_red))]\n",
    "                   \n",
    "\n",
    "ax1.legend(handles=legend_scatter, loc='upper left')\n",
    "ax2.legend(handles=legend_kde, loc='upper left') #bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# for i in range(len(noise_list_red)):\n",
    "#      kde.annotate('{0:0.1f}'.format(noise_percent[-i]), xy=(noise_mean_t[-i], 0.05*(1-i)), xycoords='data',\n",
    "#                   horizontalalignment='center', color=palette[-i], bbox=dict(facecolor='white', alpha=0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oop",
   "language": "python",
   "name": "oop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
